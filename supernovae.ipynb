{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/canoztas/CMP684-Neural-Networks-supernovae/blob/main/supernovae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqmyni5GYzPJ",
        "outputId": "e03a906d-a70f-4687-a41f-4683d7c5cc18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lqpPYVuQ9_PQ"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wkuRQB-bKN6x"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def read_data(filename): #Read data from a pickled file to a pandas DataFrame.\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    X = to_dataframe(data)\n",
        "    y = pd.get_dummies(X['type'] == 0, prefix='SNIa', drop_first=True)\n",
        "    X = X.drop(columns=['comment', 'type'])\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def to_dataframe(data): #Converts from a Python dictionary to a pandas DataFrame.\n",
        "    for idx, sn in data.items():\n",
        "        for filt in 'griz':\n",
        "            sn[f'mjd_{filt}'] = np.array(sn[filt]['mjd'])\n",
        "            sn[f'fluxcal_{filt}'] = np.array(sn[filt]['fluxcal'])\n",
        "            sn[f'fluxcalerr_{filt}'] = np.array(sn[filt]['fluxcalerr'])\n",
        "            del sn[filt]\n",
        "        sn.update(sn['header'])\n",
        "        del sn['header']\n",
        "\n",
        "    return pd.DataFrame.from_dict(data, orient='index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "gvLV9hz1WBGR"
      },
      "outputs": [],
      "source": [
        "X_train_raw, y_train = read_data('/content/drive/MyDrive/dataset/neuralnetwork/des_train.pkl')\n",
        "X_test_raw, y_test = read_data('/content/drive/MyDrive/dataset/neuralnetwork/des_test.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IvOaiUElIvva"
      },
      "outputs": [],
      "source": [
        "def bazin(time, A, B, t0, tfall, trise):\n",
        "    X = np.exp(-(time - t0) / tfall) / (1 + np.exp((time - t0) / trise))\n",
        "    return A * X + B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Qafek9U2IyGW"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize import least_squares\n",
        "\n",
        "def lightcurve_fit(time, flux):\n",
        "    scaled_time = time - time.min()\n",
        "    t0 = scaled_time[flux.argmax()]\n",
        "    guess = (0, 0, t0, 40, -5)\n",
        "\n",
        "    errfunc = lambda params: abs(flux - bazin(scaled_time, *params))\n",
        "\n",
        "    result = least_squares(errfunc, guess, method='lm')\n",
        "\n",
        "    return result.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SEw_3Q_-I0xv"
      },
      "outputs": [],
      "source": [
        "def uncertain_mean(flux, flux_err, w):\n",
        "    UM = [x / y if y != 0 else x for x, y in zip(flux, flux_err)]\n",
        "\n",
        "    if w != 0:\n",
        "        return sum(UM) / w\n",
        "    return sum(UM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VX5NO9dXI3Di"
      },
      "outputs": [],
      "source": [
        "def uncertain_moving_average(flux, flux_err, w):\n",
        "    l = len(flux)\n",
        "    UMA = []\n",
        "\n",
        "    if l <= 2 * w:\n",
        "        UMA = flux\n",
        "    else:\n",
        "        for i in range(l):\n",
        "            if i <= l - w:\n",
        "                um = uncertain_mean(flux[i:i + w], flux_err[i:i + w], w)\n",
        "            else:\n",
        "                um = uncertain_mean(flux[i:l], flux_err[i:l], l - i)\n",
        "\n",
        "            UMA.append(um)\n",
        "\n",
        "    return UMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-_HpmhOqI5QH"
      },
      "outputs": [],
      "source": [
        "def znormalization(UMA):\n",
        "    array_UMA = np.array(UMA)\n",
        "    m = np.mean(array_UMA)\n",
        "    std = np.std(array_UMA)\n",
        "    zUMA = [(x - m)/std  for x in UMA]\n",
        "    return zUMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jPgmc3ilJBNj"
      },
      "outputs": [],
      "source": [
        "def preprocessing(data):\n",
        "    #Window length for computing uncertain moving average filtering\n",
        "    w = 10\n",
        "    DES_FILTERS = 'griz'\n",
        "    # Create palceholder for output matrix\n",
        "    full_params = np.zeros((len(data), 5 * len(DES_FILTERS)))\n",
        "    # Iterate over supernovae\n",
        "    for idx, snid in enumerate(data.index):\n",
        "        params = np.zeros((len(DES_FILTERS), 5))\n",
        "        # Iterate over filters\n",
        "        for id_f, f in enumerate(DES_FILTERS):\n",
        "            time = data.loc[snid, 'mjd_%s' % f]\n",
        "            flux = data.loc[snid, 'fluxcal_%s' % f]\n",
        "            flux_err = data.loc[snid, 'fluxcalerr_%s' % f]\n",
        "\n",
        "            flux_uma = uncertain_moving_average(flux, flux_err, w)\n",
        "            flux_zuma = znormalization(flux_uma)\n",
        "            flux_zuma = np.array(flux_zuma)\n",
        "            try:\n",
        "                params[id_f] = lightcurve_fit(time,  flux_zuma)\n",
        "            except ValueError:\n",
        "                # If fit does not converge leave zeros\n",
        "                continue\n",
        "        full_params[idx] = params.ravel()\n",
        "\n",
        "    return full_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "W5BwvZK4JDWA"
      },
      "outputs": [],
      "source": [
        "X_train = preprocessing(X_train_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "ZHc9_lFW_nVo"
      },
      "outputs": [],
      "source": [
        "X_test = preprocessing(X_test_raw)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.to_numpy()"
      ],
      "metadata": {
        "id": "XF4BC7wpdsLE"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = y_test.to_numpy()"
      ],
      "metadata": {
        "id": "8Kfid6-hdwTc"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OEEERcT29C5m"
      },
      "outputs": [],
      "source": [
        "# Sigmoid and tanh activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "IhrT-LAG9Hy0"
      },
      "outputs": [],
      "source": [
        "def neural_network(isZincluded,epoch,lr,X_train,y_train,X_test):\n",
        "  # Assuming 4 filters (g, r, i, z) are used in the light curve. If used input size = 20 if not input size = 16\n",
        "  input_size = 14\n",
        "  if isZincluded:\n",
        "    input_size = 20\n",
        "\n",
        "  # Initialize weights and biases for the hidden layer\n",
        "  hidden_weights = np.random.randn(input_size, 500)\n",
        "  hidden_biases = np.zeros((1, 500))\n",
        "\n",
        "  # Initialize weights and biases for the output layer\n",
        "  output_weights = np.random.randn(500, 1)\n",
        "  output_biases = np.zeros((1, 1))\n",
        "\n",
        "  # Training parameters\n",
        "  learning_rate = lr\n",
        "  epochs = epoch\n",
        "  batch_size = 16\n",
        "  validation_split = 0.1\n",
        "  start_training(X_train,y_train,epoch,lr,validation_split,hidden_weights,hidden_biases,output_weights,output_biases,X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "gZYgURnR9LF4"
      },
      "outputs": [],
      "source": [
        "def start_training(X_train,y_train,epochs,learning_rate,validation_split,hidden_weights,hidden_biases,output_weights,output_biases,X_test):\n",
        "  # Training loop\n",
        "  for epoch in range(epochs):\n",
        "      # Forward pass\n",
        "      hidden_layer_input = np.dot(X_train, hidden_weights) + hidden_biases\n",
        "      hidden_layer_output = tanh(hidden_layer_input)\n",
        "\n",
        "      output_layer_input = np.dot(hidden_layer_output, output_weights) + output_biases\n",
        "      output_layer_output = sigmoid(output_layer_input)\n",
        "\n",
        "      # Compute loss (assuming binary cross-entropy)\n",
        "      loss = -np.mean(y_train * np.log(output_layer_output) + (1 - y_train) * np.log(1 - output_layer_output))\n",
        "\n",
        "      # Backward pass\n",
        "      output_error = output_layer_output - y_train\n",
        "      hidden_error = np.dot(output_error, output_weights.T) * (1 - np.square(hidden_layer_output))\n",
        "\n",
        "      # Update weights and biases\n",
        "      output_weights -= learning_rate * np.dot(hidden_layer_output.T, output_error) / len(X_train)\n",
        "      output_biases -= learning_rate * np.sum(output_error, axis=0, keepdims=True) / len(X_train)\n",
        "\n",
        "      hidden_weights -= learning_rate * np.dot(X_train.T, hidden_error) / len(X_train)\n",
        "      hidden_biases -= learning_rate * np.sum(hidden_error, axis=0, keepdims=True) / len(X_train)\n",
        "\n",
        "      # Validation loss\n",
        "      if epoch % 10 == 0:\n",
        "          val_hidden_layer_output = tanh(np.dot(X_train[int(X_train.shape[0] * (1 - validation_split)):], hidden_weights) + hidden_biases)\n",
        "          val_output_layer_output = sigmoid(np.dot(val_hidden_layer_output, output_weights) + output_biases)\n",
        "          val_loss = -np.mean(y_train[int(X_train.shape[0] * (1 - validation_split)):] * np.log(val_output_layer_output) +\n",
        "                              (1 - y_train[int(X_train.shape[0] * (1 - validation_split)):]) * np.log(1 - val_output_layer_output))\n",
        "          print(f\"Epoch {epoch}/{epochs}, Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "  prediction(hidden_weights,hidden_biases,output_weights,output_biases,X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JlJNJYC2-EPh"
      },
      "outputs": [],
      "source": [
        "def prediction(hidden_weights,hidden_biases,output_weights,output_biases,X_test):\n",
        "  # Prediction\n",
        "  test_hidden_layer_output = tanh(np.dot(X_test, hidden_weights) + hidden_biases)\n",
        "  y_pred = sigmoid(np.dot(test_hidden_layer_output, output_weights) + output_biases)\n",
        "  calculate_results(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "rbM5PfqIFUxO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def calculate_metrics(true_labels, predicted_probs, threshold=0.5, penalty_factor=3):\n",
        "    # Convert probabilities to class labels based on the threshold\n",
        "    predicted_labels = (predicted_probs > threshold).astype(int)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "    # Extract values from the confusion matrix\n",
        "    N_total_Ia = cm[1, :].sum()\n",
        "    N_true_Ia = cm[1, 1]\n",
        "    N_false_Ia = cm[0, 1]\n",
        "\n",
        "    # Completeness\n",
        "    completeness_Ia = N_true_Ia / N_total_Ia\n",
        "\n",
        "    # Purity\n",
        "    purity_Ia = N_true_Ia / (N_true_Ia + N_false_Ia)\n",
        "\n",
        "    # SNPCC Figure of Merit\n",
        "    FIa = (N_true_Ia ** 2) / (N_total_Ia * (N_true_Ia + penalty_factor * N_false_Ia))\n",
        "\n",
        "    return completeness_Ia, purity_Ia, FIa\n",
        "\n",
        "def calculate_results(y_pred):\n",
        "  true_labels = y_test\n",
        "  predicted_probs = y_pred\n",
        "\n",
        "  threshold = 0.5\n",
        "  penalty_factor = 3\n",
        "\n",
        "  completeness, purity, figure_of_merit = calculate_metrics(true_labels, predicted_probs, threshold, penalty_factor)\n",
        "\n",
        "  print(\"Completeness:\", completeness)\n",
        "  GLOBAL_COMPLETENESS.append(completeness)\n",
        "  print(\"Purity:\", purity)\n",
        "  GLOBAL_PURITY.append(purity)\n",
        "  print(\"SNPCC Figure of Merit:\", figure_of_merit)\n",
        "  GLOBAL_FOM.append(figure_of_merit)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GLOBAL_SAMPLE_SIZE = []\n",
        "GLOBAL_Z_USED = []\n",
        "GLOBAL_COMPLETENESS = []\n",
        "GLOBAL_PURITY = []\n",
        "GLOBAL_FOM = []"
      ],
      "metadata": {
        "id": "-Uvtzft0K3Nu"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of elements to select\n",
        "percentages = [5,10,20,30,40,50,100]\n",
        "for percentage in percentages:\n",
        "  num_elements_to_select = int(len(X_train) * (percentage / 100.0))\n",
        "\n",
        "  # Use numpy.random.choice to get random indices\n",
        "  random_indices = np.random.choice(len(X_train), size=num_elements_to_select, replace=False)\n",
        "\n",
        "  # Get the selected elements from the original array\n",
        "  X_train_local = X_train[random_indices]\n",
        "  tmp = pd.DataFrame(X_train_local).iloc[:,:9]\n",
        "  tmp = tmp.join(pd.DataFrame(X_train_local).iloc[:,12])\n",
        "  tmp = tmp.join(pd.DataFrame(X_train_local).iloc[:,14:18])\n",
        "  X_train_local = tmp.to_numpy()\n",
        "\n",
        "  y_train_local = y_train[random_indices]\n",
        "\n",
        "  X_test_local = X_test\n",
        "  tmp = pd.DataFrame(X_test_local).iloc[:,:9]\n",
        "  tmp = tmp.join(pd.DataFrame(X_test_local).iloc[:,12])\n",
        "  tmp = tmp.join(pd.DataFrame(X_test_local).iloc[:,14:18])\n",
        "  X_test_local = tmp.to_numpy()\n",
        "\n",
        "  GLOBAL_SAMPLE_SIZE.append(percentage)\n",
        "  GLOBAL_Z_USED.append('no')\n",
        "  neural_network(False,500,0.3,X_train_local,y_train_local,X_test_local)\n",
        "  print(percentage)"
      ],
      "metadata": {
        "id": "X81wEO5tjU44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ecef416-46b7-4a94-ed1e-e8c57ba0b7d8"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/500, Loss: nan, Validation Loss: 1.9424\n",
            "Epoch 10/500, Loss: nan, Validation Loss: 2.5785\n",
            "Epoch 20/500, Loss: nan, Validation Loss: 0.8464\n",
            "Epoch 30/500, Loss: 1.6705, Validation Loss: 2.2209\n",
            "Epoch 40/500, Loss: 2.6152, Validation Loss: 1.1359\n",
            "Epoch 50/500, Loss: 2.3152, Validation Loss: 2.8670\n",
            "Epoch 60/500, Loss: 0.7698, Validation Loss: 1.3195\n",
            "Epoch 70/500, Loss: 1.1931, Validation Loss: 1.5157\n",
            "Epoch 80/500, Loss: 0.7663, Validation Loss: 1.2323\n",
            "Epoch 90/500, Loss: 0.8791, Validation Loss: 0.4068\n",
            "Epoch 100/500, Loss: 0.5818, Validation Loss: 0.6922\n",
            "Epoch 110/500, Loss: 1.4066, Validation Loss: 2.0736\n",
            "Epoch 120/500, Loss: 0.2947, Validation Loss: 0.1092\n",
            "Epoch 130/500, Loss: 0.5270, Validation Loss: 0.5913\n",
            "Epoch 140/500, Loss: 0.5686, Validation Loss: 1.0757\n",
            "Epoch 150/500, Loss: 0.2991, Validation Loss: 0.4188\n",
            "Epoch 160/500, Loss: 0.2001, Validation Loss: 0.2374\n",
            "Epoch 170/500, Loss: 0.2428, Validation Loss: 0.3228\n",
            "Epoch 180/500, Loss: 0.2347, Validation Loss: 0.2961\n",
            "Epoch 190/500, Loss: 0.2197, Validation Loss: 0.2526\n",
            "Epoch 200/500, Loss: 0.2107, Validation Loss: 0.2162\n",
            "Epoch 210/500, Loss: 0.2007, Validation Loss: 0.1862\n",
            "Epoch 220/500, Loss: 0.1911, Validation Loss: 0.1587\n",
            "Epoch 230/500, Loss: 0.1890, Validation Loss: 0.1417\n",
            "Epoch 240/500, Loss: 0.1795, Validation Loss: 0.1223\n",
            "Epoch 250/500, Loss: 0.1832, Validation Loss: 0.1244\n",
            "Epoch 260/500, Loss: 2.0736, Validation Loss: 2.9372\n",
            "Epoch 270/500, Loss: 0.6559, Validation Loss: 0.0706\n",
            "Epoch 280/500, Loss: 0.4780, Validation Loss: 0.1298\n",
            "Epoch 290/500, Loss: 0.3633, Validation Loss: 0.3820\n",
            "Epoch 300/500, Loss: 0.3879, Validation Loss: 0.3757\n",
            "Epoch 310/500, Loss: 0.3505, Validation Loss: 0.3836\n",
            "Epoch 320/500, Loss: 0.3207, Validation Loss: 0.3553\n",
            "Epoch 330/500, Loss: 0.2941, Validation Loss: 0.3177\n",
            "Epoch 340/500, Loss: 0.2747, Validation Loss: 0.2876\n",
            "Epoch 350/500, Loss: 0.2614, Validation Loss: 0.2669\n",
            "Epoch 360/500, Loss: 0.2524, Validation Loss: 0.2514\n",
            "Epoch 370/500, Loss: 0.2446, Validation Loss: 0.2383\n",
            "Epoch 380/500, Loss: 0.2381, Validation Loss: 0.2284\n",
            "Epoch 390/500, Loss: 0.2325, Validation Loss: 0.2177\n",
            "Epoch 400/500, Loss: 0.2274, Validation Loss: 0.2093\n",
            "Epoch 410/500, Loss: 0.2226, Validation Loss: 0.2007\n",
            "Epoch 420/500, Loss: 0.2174, Validation Loss: 0.1917\n",
            "Epoch 430/500, Loss: 0.2128, Validation Loss: 0.1832\n",
            "Epoch 440/500, Loss: 0.2074, Validation Loss: 0.1739\n",
            "Epoch 450/500, Loss: 0.2033, Validation Loss: 0.1665\n",
            "Epoch 460/500, Loss: 0.1990, Validation Loss: 0.1576\n",
            "Epoch 470/500, Loss: 0.2048, Validation Loss: 0.1542\n",
            "Epoch 480/500, Loss: 0.2031, Validation Loss: 0.1512\n",
            "Epoch 490/500, Loss: 0.2007, Validation Loss: 0.1478\n",
            "Completeness: 0.6758666372267609\n",
            "Purity: 0.2501634521085322\n",
            "SNPCC Figure of Merit: 0.06763969713434627\n",
            "5\n",
            "Epoch 0/500, Loss: nan, Validation Loss: 2.8193\n",
            "Epoch 10/500, Loss: nan, Validation Loss: 1.6812\n",
            "Epoch 20/500, Loss: nan, Validation Loss: 1.1777\n",
            "Epoch 30/500, Loss: 2.6816, Validation Loss: 1.9151\n",
            "Epoch 40/500, Loss: 3.6561, Validation Loss: 1.3170\n",
            "Epoch 50/500, Loss: 3.3342, Validation Loss: 0.7100\n",
            "Epoch 60/500, Loss: 2.2185, Validation Loss: 0.8663\n",
            "Epoch 70/500, Loss: 2.7008, Validation Loss: 0.8770\n",
            "Epoch 80/500, Loss: 2.3173, Validation Loss: 0.9506\n",
            "Epoch 90/500, Loss: 1.1506, Validation Loss: 1.4330\n",
            "Epoch 100/500, Loss: 1.6324, Validation Loss: 1.1894\n",
            "Epoch 110/500, Loss: 0.7552, Validation Loss: 1.2775\n",
            "Epoch 120/500, Loss: 1.5102, Validation Loss: 1.2453\n",
            "Epoch 130/500, Loss: 0.5966, Validation Loss: 1.0919\n",
            "Epoch 140/500, Loss: 2.2864, Validation Loss: 1.0885\n",
            "Epoch 150/500, Loss: 1.3047, Validation Loss: 1.1839\n",
            "Epoch 160/500, Loss: 1.6912, Validation Loss: 1.0651\n",
            "Epoch 170/500, Loss: 0.5830, Validation Loss: 1.0818\n",
            "Epoch 180/500, Loss: 0.2506, Validation Loss: 0.5123\n",
            "Epoch 190/500, Loss: 0.3904, Validation Loss: 1.5121\n",
            "Epoch 200/500, Loss: 2.2922, Validation Loss: 0.8528\n",
            "Epoch 210/500, Loss: 0.4966, Validation Loss: 1.3223\n",
            "Epoch 220/500, Loss: 0.8634, Validation Loss: 1.9222\n",
            "Epoch 230/500, Loss: 0.6707, Validation Loss: 1.9003\n",
            "Epoch 240/500, Loss: 1.7569, Validation Loss: 0.9197\n",
            "Epoch 250/500, Loss: 0.3145, Validation Loss: 0.6730\n",
            "Epoch 260/500, Loss: nan, Validation Loss: 0.8106\n",
            "Epoch 270/500, Loss: 1.6708, Validation Loss: 1.0801\n",
            "Epoch 280/500, Loss: 0.3153, Validation Loss: 0.8344\n",
            "Epoch 290/500, Loss: 0.2001, Validation Loss: 0.5168\n",
            "Epoch 300/500, Loss: 0.7880, Validation Loss: 2.2474\n",
            "Epoch 310/500, Loss: 0.2254, Validation Loss: 0.6073\n",
            "Epoch 320/500, Loss: 0.2528, Validation Loss: 0.7520\n",
            "Epoch 330/500, Loss: 0.8320, Validation Loss: 2.0693\n",
            "Epoch 340/500, Loss: 0.4542, Validation Loss: 1.8131\n",
            "Epoch 350/500, Loss: 1.8930, Validation Loss: 0.6324\n",
            "Epoch 360/500, Loss: 0.2050, Validation Loss: 0.5590\n",
            "Epoch 370/500, Loss: 0.7025, Validation Loss: 2.1196\n",
            "Epoch 380/500, Loss: 0.8172, Validation Loss: 2.0104\n",
            "Epoch 390/500, Loss: 0.2920, Validation Loss: 0.7967\n",
            "Epoch 400/500, Loss: 1.0101, Validation Loss: 1.6641\n",
            "Epoch 410/500, Loss: 0.1710, Validation Loss: 0.4064\n",
            "Epoch 420/500, Loss: nan, Validation Loss: 0.5437\n",
            "Epoch 430/500, Loss: nan, Validation Loss: 0.6371\n",
            "Epoch 440/500, Loss: 0.1858, Validation Loss: 0.6225\n",
            "Epoch 450/500, Loss: 0.2411, Validation Loss: 0.8160\n",
            "Epoch 460/500, Loss: 1.7407, Validation Loss: 0.7063\n",
            "Epoch 470/500, Loss: 0.2457, Validation Loss: 0.6718\n",
            "Epoch 480/500, Loss: 1.5364, Validation Loss: 0.8887\n",
            "Epoch 490/500, Loss: 0.9437, Validation Loss: 1.7280\n",
            "Completeness: 0.7438728196069773\n",
            "Purity: 0.23534753754802654\n",
            "SNPCC Figure of Merit: 0.06921610542867143\n",
            "10\n",
            "Epoch 0/500, Loss: nan, Validation Loss: nan\n",
            "Epoch 10/500, Loss: 3.5246, Validation Loss: nan\n",
            "Epoch 20/500, Loss: 3.2334, Validation Loss: nan\n",
            "Epoch 30/500, Loss: 1.5733, Validation Loss: 1.4888\n",
            "Epoch 40/500, Loss: 1.4740, Validation Loss: nan\n",
            "Epoch 50/500, Loss: 1.2621, Validation Loss: 2.5591\n",
            "Epoch 60/500, Loss: 1.1790, Validation Loss: 2.6869\n",
            "Epoch 70/500, Loss: 1.1416, Validation Loss: 2.2249\n",
            "Epoch 80/500, Loss: 0.8828, Validation Loss: 2.1159\n",
            "Epoch 90/500, Loss: 1.1118, Validation Loss: 2.9834\n",
            "Epoch 100/500, Loss: 0.6415, Validation Loss: 1.5359\n",
            "Epoch 110/500, Loss: 0.6344, Validation Loss: 1.1349\n",
            "Epoch 120/500, Loss: 0.5692, Validation Loss: 1.1726\n",
            "Epoch 130/500, Loss: 0.4166, Validation Loss: 0.7957\n",
            "Epoch 140/500, Loss: 0.7298, Validation Loss: 1.8182\n",
            "Epoch 150/500, Loss: 0.8033, Validation Loss: 1.7622\n",
            "Epoch 160/500, Loss: 0.2182, Validation Loss: 0.4898\n",
            "Epoch 170/500, Loss: 0.1627, Validation Loss: 0.3498\n",
            "Epoch 180/500, Loss: 0.1308, Validation Loss: 0.2346\n",
            "Epoch 190/500, Loss: 0.2119, Validation Loss: 0.9624\n",
            "Epoch 200/500, Loss: 1.0880, Validation Loss: nan\n",
            "Epoch 210/500, Loss: 0.9726, Validation Loss: 2.6369\n",
            "Epoch 220/500, Loss: 0.4647, Validation Loss: 0.8580\n",
            "Epoch 230/500, Loss: 0.7414, Validation Loss: 2.5994\n",
            "Epoch 240/500, Loss: 0.2964, Validation Loss: 0.6522\n",
            "Epoch 250/500, Loss: 0.5383, Validation Loss: 1.1579\n",
            "Epoch 260/500, Loss: nan, Validation Loss: 0.2041\n",
            "Epoch 270/500, Loss: nan, Validation Loss: 0.1272\n",
            "Epoch 280/500, Loss: nan, Validation Loss: 0.1183\n",
            "Epoch 290/500, Loss: nan, Validation Loss: 0.1378\n",
            "Epoch 300/500, Loss: 1.2318, Validation Loss: nan\n",
            "Epoch 310/500, Loss: 0.4646, Validation Loss: 1.0894\n",
            "Epoch 320/500, Loss: 0.1984, Validation Loss: 0.2989\n",
            "Epoch 330/500, Loss: 0.1353, Validation Loss: 0.2137\n",
            "Epoch 340/500, Loss: 0.1584, Validation Loss: 0.3551\n",
            "Epoch 350/500, Loss: 0.3359, Validation Loss: 0.3363\n",
            "Epoch 360/500, Loss: 0.1383, Validation Loss: 0.2102\n",
            "Epoch 370/500, Loss: 0.1250, Validation Loss: 0.2185\n",
            "Epoch 380/500, Loss: 0.6970, Validation Loss: 1.3885\n",
            "Epoch 390/500, Loss: 0.8186, Validation Loss: 2.0137\n",
            "Epoch 400/500, Loss: 0.1783, Validation Loss: 0.2203\n",
            "Epoch 410/500, Loss: 0.1489, Validation Loss: 0.2103\n",
            "Epoch 420/500, Loss: 0.1284, Validation Loss: 0.1681\n",
            "Epoch 430/500, Loss: nan, Validation Loss: 0.8451\n",
            "Epoch 440/500, Loss: 0.1562, Validation Loss: 0.1977\n",
            "Epoch 450/500, Loss: 0.1283, Validation Loss: 0.1614\n",
            "Epoch 460/500, Loss: 0.2123, Validation Loss: 0.2885\n",
            "Epoch 470/500, Loss: 0.1876, Validation Loss: 0.2530\n",
            "Epoch 480/500, Loss: 0.1371, Validation Loss: 0.1756\n",
            "Epoch 490/500, Loss: 0.1286, Validation Loss: 0.1652\n",
            "Completeness: 0.5784941488187237\n",
            "Purity: 0.2808145766345123\n",
            "SNPCC Figure of Merit: 0.06662218329252995\n",
            "20\n",
            "Epoch 0/500, Loss: 5.6167, Validation Loss: nan\n",
            "Epoch 10/500, Loss: 3.1903, Validation Loss: 0.8401\n",
            "Epoch 20/500, Loss: 4.9763, Validation Loss: nan\n",
            "Epoch 30/500, Loss: 2.0097, Validation Loss: 0.2830\n",
            "Epoch 40/500, Loss: 1.7955, Validation Loss: 4.1330\n",
            "Epoch 50/500, Loss: 1.2867, Validation Loss: 0.2600\n",
            "Epoch 60/500, Loss: 1.1800, Validation Loss: 3.1353\n",
            "Epoch 70/500, Loss: 2.8039, Validation Loss: 2.2399\n",
            "Epoch 80/500, Loss: 1.2565, Validation Loss: 0.5401\n",
            "Epoch 90/500, Loss: 1.2101, Validation Loss: 1.3085\n",
            "Epoch 100/500, Loss: 3.7878, Validation Loss: 0.3660\n",
            "Epoch 110/500, Loss: 2.3176, Validation Loss: 0.4925\n",
            "Epoch 120/500, Loss: 0.8163, Validation Loss: 0.4729\n",
            "Epoch 130/500, Loss: 2.4509, Validation Loss: 0.2361\n",
            "Epoch 140/500, Loss: 1.2093, Validation Loss: 0.7541\n",
            "Epoch 150/500, Loss: 2.4321, Validation Loss: 0.1925\n",
            "Epoch 160/500, Loss: 0.6263, Validation Loss: 0.3125\n",
            "Epoch 170/500, Loss: 2.0786, Validation Loss: 0.6896\n",
            "Epoch 180/500, Loss: 1.5219, Validation Loss: 0.1058\n",
            "Epoch 190/500, Loss: 0.4386, Validation Loss: 0.4459\n",
            "Epoch 200/500, Loss: 2.4235, Validation Loss: 0.1195\n",
            "Epoch 210/500, Loss: 1.4546, Validation Loss: 0.4053\n",
            "Epoch 220/500, Loss: 3.1728, Validation Loss: 0.5039\n",
            "Epoch 230/500, Loss: 0.5506, Validation Loss: 0.3054\n",
            "Epoch 240/500, Loss: 0.6742, Validation Loss: 0.7284\n",
            "Epoch 250/500, Loss: 1.4826, Validation Loss: 0.0814\n",
            "Epoch 260/500, Loss: nan, Validation Loss: 0.4737\n",
            "Epoch 270/500, Loss: 0.4805, Validation Loss: 0.4955\n",
            "Epoch 280/500, Loss: nan, Validation Loss: 0.2918\n",
            "Epoch 290/500, Loss: 0.5721, Validation Loss: 0.4714\n",
            "Epoch 300/500, Loss: 1.3126, Validation Loss: 0.0998\n",
            "Epoch 310/500, Loss: nan, Validation Loss: 0.4487\n",
            "Epoch 320/500, Loss: nan, Validation Loss: 0.0736\n",
            "Epoch 330/500, Loss: nan, Validation Loss: 0.2199\n",
            "Epoch 340/500, Loss: 0.3635, Validation Loss: 0.4853\n",
            "Epoch 350/500, Loss: 0.4492, Validation Loss: 0.6670\n",
            "Epoch 360/500, Loss: nan, Validation Loss: 0.0673\n",
            "Epoch 370/500, Loss: nan, Validation Loss: 0.4090\n",
            "Epoch 380/500, Loss: nan, Validation Loss: 0.0938\n",
            "Epoch 390/500, Loss: nan, Validation Loss: nan\n",
            "Epoch 400/500, Loss: nan, Validation Loss: nan\n",
            "Epoch 410/500, Loss: nan, Validation Loss: nan\n",
            "Epoch 420/500, Loss: nan, Validation Loss: nan\n",
            "Epoch 430/500, Loss: nan, Validation Loss: nan\n",
            "Epoch 440/500, Loss: nan, Validation Loss: nan\n",
            "Epoch 450/500, Loss: nan, Validation Loss: nan\n",
            "Epoch 460/500, Loss: nan, Validation Loss: nan\n",
            "Epoch 470/500, Loss: nan, Validation Loss: nan\n",
            "Epoch 480/500, Loss: nan, Validation Loss: nan\n",
            "Epoch 490/500, Loss: nan, Validation Loss: nan\n",
            "Completeness: 0.833296533451093\n",
            "Purity: 0.24899386422115194\n",
            "SNPCC Figure of Merit: 0.08292754047001621\n",
            "30\n",
            "Epoch 0/500, Loss: 10.6411, Validation Loss: nan\n",
            "Epoch 10/500, Loss: 3.7746, Validation Loss: 4.2961\n",
            "Epoch 20/500, Loss: 2.5250, Validation Loss: 1.1448\n",
            "Epoch 30/500, Loss: 5.0759, Validation Loss: nan\n",
            "Epoch 40/500, Loss: 1.6548, Validation Loss: 0.8720\n",
            "Epoch 50/500, Loss: 2.7159, Validation Loss: nan\n",
            "Epoch 60/500, Loss: 3.3185, Validation Loss: nan\n",
            "Epoch 70/500, Loss: 1.2751, Validation Loss: 0.5359\n",
            "Epoch 80/500, Loss: 0.8477, Validation Loss: 1.3875\n",
            "Epoch 90/500, Loss: 1.3346, Validation Loss: 3.4870\n",
            "Epoch 100/500, Loss: 2.0186, Validation Loss: 2.8426\n",
            "Epoch 110/500, Loss: 0.9366, Validation Loss: 0.7987\n",
            "Epoch 120/500, Loss: 0.6308, Validation Loss: 1.1337\n",
            "Epoch 130/500, Loss: 1.2661, Validation Loss: 2.6737\n",
            "Epoch 140/500, Loss: 1.5193, Validation Loss: 1.6062\n",
            "Epoch 150/500, Loss: 0.7465, Validation Loss: 0.1138\n",
            "Epoch 160/500, Loss: 0.5762, Validation Loss: 0.3169\n",
            "Epoch 170/500, Loss: nan, Validation Loss: 0.6942\n",
            "Epoch 180/500, Loss: 0.8078, Validation Loss: 1.7965\n",
            "Epoch 190/500, Loss: 1.1441, Validation Loss: 2.3764\n",
            "Epoch 200/500, Loss: 1.4393, Validation Loss: 1.4665\n",
            "Epoch 210/500, Loss: 0.7389, Validation Loss: 0.2947\n",
            "Epoch 220/500, Loss: 0.3891, Validation Loss: 0.2584\n",
            "Epoch 230/500, Loss: 0.4190, Validation Loss: 0.4907\n",
            "Epoch 240/500, Loss: 0.4634, Validation Loss: 0.5488\n",
            "Epoch 250/500, Loss: 0.6877, Validation Loss: 1.1586\n",
            "Epoch 260/500, Loss: 0.6640, Validation Loss: 0.6606\n",
            "Epoch 270/500, Loss: 0.4558, Validation Loss: 0.4022\n",
            "Epoch 280/500, Loss: 0.6566, Validation Loss: 1.1277\n",
            "Epoch 290/500, Loss: 0.5234, Validation Loss: 0.7930\n",
            "Epoch 300/500, Loss: 0.6141, Validation Loss: 1.2656\n",
            "Epoch 310/500, Loss: 0.8089, Validation Loss: 1.5640\n",
            "Epoch 320/500, Loss: 0.7391, Validation Loss: 1.2000\n",
            "Epoch 330/500, Loss: 0.7694, Validation Loss: 1.1785\n",
            "Epoch 340/500, Loss: 0.6230, Validation Loss: 0.6486\n",
            "Epoch 350/500, Loss: 0.4512, Validation Loss: 0.4874\n",
            "Epoch 360/500, Loss: 0.4783, Validation Loss: 0.6240\n",
            "Epoch 370/500, Loss: 0.4172, Validation Loss: 0.5817\n",
            "Epoch 380/500, Loss: 0.4637, Validation Loss: 0.5134\n",
            "Epoch 390/500, Loss: 0.3657, Validation Loss: 0.4967\n",
            "Epoch 400/500, Loss: 0.6105, Validation Loss: 0.3782\n",
            "Epoch 410/500, Loss: 0.4107, Validation Loss: 0.2003\n",
            "Epoch 420/500, Loss: 0.4101, Validation Loss: 0.4492\n",
            "Epoch 430/500, Loss: 0.3336, Validation Loss: 0.3124\n",
            "Epoch 440/500, Loss: 0.3906, Validation Loss: 0.4409\n",
            "Epoch 450/500, Loss: 0.3229, Validation Loss: 0.3101\n",
            "Epoch 460/500, Loss: 0.3631, Validation Loss: 0.4268\n",
            "Epoch 470/500, Loss: 0.2853, Validation Loss: 0.2276\n",
            "Epoch 480/500, Loss: 0.3547, Validation Loss: 0.3984\n",
            "Epoch 490/500, Loss: 0.3344, Validation Loss: 0.2646\n",
            "Completeness: 0.4767056745418415\n",
            "Purity: 0.2980397570403092\n",
            "SNPCC Figure of Merit: 0.05910230569288134\n",
            "40\n",
            "Epoch 0/500, Loss: nan, Validation Loss: 7.7849\n",
            "Epoch 10/500, Loss: nan, Validation Loss: 3.4423\n",
            "Epoch 20/500, Loss: nan, Validation Loss: 3.3296\n",
            "Epoch 30/500, Loss: nan, Validation Loss: 3.6623\n",
            "Epoch 40/500, Loss: nan, Validation Loss: 2.7878\n",
            "Epoch 50/500, Loss: nan, Validation Loss: 1.9755\n",
            "Epoch 60/500, Loss: nan, Validation Loss: 2.2063\n",
            "Epoch 70/500, Loss: nan, Validation Loss: 2.8539\n",
            "Epoch 80/500, Loss: nan, Validation Loss: 2.0769\n",
            "Epoch 90/500, Loss: nan, Validation Loss: 2.2534\n",
            "Epoch 100/500, Loss: nan, Validation Loss: 2.5612\n",
            "Epoch 110/500, Loss: nan, Validation Loss: 1.3996\n",
            "Epoch 120/500, Loss: nan, Validation Loss: 2.3455\n",
            "Epoch 130/500, Loss: nan, Validation Loss: 2.6700\n",
            "Epoch 140/500, Loss: nan, Validation Loss: 2.0131\n",
            "Epoch 150/500, Loss: nan, Validation Loss: 2.5466\n",
            "Epoch 160/500, Loss: nan, Validation Loss: 2.7078\n",
            "Epoch 170/500, Loss: nan, Validation Loss: 1.6454\n",
            "Epoch 180/500, Loss: nan, Validation Loss: 2.5204\n",
            "Epoch 190/500, Loss: nan, Validation Loss: 1.5199\n",
            "Epoch 200/500, Loss: nan, Validation Loss: 2.3449\n",
            "Epoch 210/500, Loss: nan, Validation Loss: 1.8338\n",
            "Epoch 220/500, Loss: nan, Validation Loss: 2.3368\n",
            "Epoch 230/500, Loss: nan, Validation Loss: 2.2500\n",
            "Epoch 240/500, Loss: nan, Validation Loss: 2.0295\n",
            "Epoch 250/500, Loss: nan, Validation Loss: 1.5957\n",
            "Epoch 260/500, Loss: nan, Validation Loss: 1.4624\n",
            "Epoch 270/500, Loss: nan, Validation Loss: 1.7812\n",
            "Epoch 280/500, Loss: nan, Validation Loss: 1.5775\n",
            "Epoch 290/500, Loss: nan, Validation Loss: 1.6608\n",
            "Epoch 300/500, Loss: nan, Validation Loss: 1.3238\n",
            "Epoch 310/500, Loss: nan, Validation Loss: 1.4916\n",
            "Epoch 320/500, Loss: nan, Validation Loss: 1.4527\n",
            "Epoch 330/500, Loss: nan, Validation Loss: 1.6366\n",
            "Epoch 340/500, Loss: nan, Validation Loss: 2.5673\n",
            "Epoch 350/500, Loss: nan, Validation Loss: 2.3223\n",
            "Epoch 360/500, Loss: nan, Validation Loss: 2.0099\n",
            "Epoch 370/500, Loss: nan, Validation Loss: 1.5910\n",
            "Epoch 380/500, Loss: nan, Validation Loss: 1.6685\n",
            "Epoch 390/500, Loss: nan, Validation Loss: 1.3973\n",
            "Epoch 400/500, Loss: nan, Validation Loss: 1.3959\n",
            "Epoch 410/500, Loss: nan, Validation Loss: 1.6743\n",
            "Epoch 420/500, Loss: nan, Validation Loss: 1.4326\n",
            "Epoch 430/500, Loss: nan, Validation Loss: 1.1927\n",
            "Epoch 440/500, Loss: nan, Validation Loss: 1.2789\n",
            "Epoch 450/500, Loss: nan, Validation Loss: 1.2722\n",
            "Epoch 460/500, Loss: nan, Validation Loss: 1.5882\n",
            "Epoch 470/500, Loss: nan, Validation Loss: 2.1093\n",
            "Epoch 480/500, Loss: nan, Validation Loss: 1.9773\n",
            "Epoch 490/500, Loss: nan, Validation Loss: 1.6802\n",
            "Completeness: 0.8602340472510488\n",
            "Purity: 0.24403382398997808\n",
            "SNPCC Figure of Merit: 0.08357159933396718\n",
            "50\n",
            "Epoch 0/500, Loss: nan, Validation Loss: 7.4858\n",
            "Epoch 10/500, Loss: nan, Validation Loss: 3.2734\n",
            "Epoch 20/500, Loss: nan, Validation Loss: 4.1271\n",
            "Epoch 30/500, Loss: 1.6732, Validation Loss: 2.1394\n",
            "Epoch 40/500, Loss: nan, Validation Loss: 3.1417\n",
            "Epoch 50/500, Loss: nan, Validation Loss: 3.6576\n",
            "Epoch 60/500, Loss: nan, Validation Loss: 1.8634\n",
            "Epoch 70/500, Loss: 2.2975, Validation Loss: 4.3313\n",
            "Epoch 80/500, Loss: nan, Validation Loss: 1.7100\n",
            "Epoch 90/500, Loss: 1.1819, Validation Loss: 2.3603\n",
            "Epoch 100/500, Loss: nan, Validation Loss: 3.1729\n",
            "Epoch 110/500, Loss: nan, Validation Loss: 1.8691\n",
            "Epoch 120/500, Loss: 1.1268, Validation Loss: 1.1774\n",
            "Epoch 130/500, Loss: nan, Validation Loss: 2.1177\n",
            "Epoch 140/500, Loss: nan, Validation Loss: 1.9255\n",
            "Epoch 150/500, Loss: nan, Validation Loss: 3.2862\n",
            "Epoch 160/500, Loss: nan, Validation Loss: 1.6429\n",
            "Epoch 170/500, Loss: 0.9908, Validation Loss: 1.1363\n",
            "Epoch 180/500, Loss: nan, Validation Loss: 2.9747\n",
            "Epoch 190/500, Loss: nan, Validation Loss: 1.7804\n",
            "Epoch 200/500, Loss: 0.9835, Validation Loss: 1.0667\n",
            "Epoch 210/500, Loss: nan, Validation Loss: 2.0596\n",
            "Epoch 220/500, Loss: nan, Validation Loss: 2.7451\n",
            "Epoch 230/500, Loss: nan, Validation Loss: 1.7598\n",
            "Epoch 240/500, Loss: 0.8188, Validation Loss: 0.9788\n",
            "Epoch 250/500, Loss: nan, Validation Loss: 1.9529\n",
            "Epoch 260/500, Loss: nan, Validation Loss: 3.0239\n",
            "Epoch 270/500, Loss: nan, Validation Loss: 1.8432\n",
            "Epoch 280/500, Loss: nan, Validation Loss: 0.9382\n",
            "Epoch 290/500, Loss: 1.1547, Validation Loss: 2.4277\n",
            "Epoch 300/500, Loss: nan, Validation Loss: 2.5149\n",
            "Epoch 310/500, Loss: nan, Validation Loss: 1.5081\n",
            "Epoch 320/500, Loss: 0.6781, Validation Loss: 1.0423\n",
            "Epoch 330/500, Loss: 1.1076, Validation Loss: 2.0585\n",
            "Epoch 340/500, Loss: nan, Validation Loss: 2.8850\n",
            "Epoch 350/500, Loss: nan, Validation Loss: 1.8012\n",
            "Epoch 360/500, Loss: 0.9443, Validation Loss: 0.9082\n",
            "Epoch 370/500, Loss: 1.0031, Validation Loss: 1.6085\n",
            "Epoch 380/500, Loss: nan, Validation Loss: 2.5415\n",
            "Epoch 390/500, Loss: nan, Validation Loss: 1.9618\n",
            "Epoch 400/500, Loss: 1.1507, Validation Loss: 1.0346\n",
            "Epoch 410/500, Loss: 0.9470, Validation Loss: 1.5533\n",
            "Epoch 420/500, Loss: nan, Validation Loss: 2.7594\n",
            "Epoch 430/500, Loss: nan, Validation Loss: 1.7793\n",
            "Epoch 440/500, Loss: 1.0773, Validation Loss: 0.9938\n",
            "Epoch 450/500, Loss: 0.8225, Validation Loss: 1.5874\n",
            "Epoch 460/500, Loss: nan, Validation Loss: 2.8624\n",
            "Epoch 470/500, Loss: nan, Validation Loss: 1.1945\n",
            "Epoch 480/500, Loss: 0.7081, Validation Loss: 0.8754\n",
            "Epoch 490/500, Loss: 0.9141, Validation Loss: 1.5851\n",
            "Completeness: 0.9092514903952308\n",
            "Purity: 0.24368305816912245\n",
            "SNPCC Figure of Merit: 0.0881820408715659\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of elements to select\n",
        "percentages = [5,10,20,30,40,50,100]\n",
        "for percentage in percentages:\n",
        "  num_elements_to_select = int(len(X_train) * (percentage / 100.0))\n",
        "\n",
        "  # Use numpy.random.choice to get random indices\n",
        "  random_indices = np.random.choice(len(X_train), size=num_elements_to_select, replace=False)\n",
        "\n",
        "  # Get the selected elements from the original array\n",
        "  X_train_local = X_train[random_indices]\n",
        "  y_train_local = y_train[random_indices]\n",
        "  X_test_local = X_test\n",
        "  GLOBAL_SAMPLE_SIZE.append(percentage)\n",
        "  GLOBAL_Z_USED.append('yes')\n",
        "  neural_network(True,500,0.3,X_train_local,y_train_local,X_test_local)\n",
        "  print(percentage)"
      ],
      "metadata": {
        "id": "pDp7iMX2Era1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c8b0e3-2d3e-47bf-a8d9-f30f33831080"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/500, Loss: 4.2217, Validation Loss: 13.9801\n",
            "Epoch 10/500, Loss: 0.4889, Validation Loss: 2.1256\n",
            "Epoch 20/500, Loss: 0.1119, Validation Loss: 0.3967\n",
            "Epoch 30/500, Loss: 0.0684, Validation Loss: 0.1508\n",
            "Epoch 40/500, Loss: 0.0397, Validation Loss: 0.0473\n",
            "Epoch 50/500, Loss: 0.0356, Validation Loss: 0.0325\n",
            "Epoch 60/500, Loss: 0.0339, Validation Loss: 0.0282\n",
            "Epoch 70/500, Loss: 0.0328, Validation Loss: 0.0252\n",
            "Epoch 80/500, Loss: 0.0320, Validation Loss: 0.0229\n",
            "Epoch 90/500, Loss: 0.0314, Validation Loss: 0.0209\n",
            "Epoch 100/500, Loss: 0.0309, Validation Loss: 0.0193\n",
            "Epoch 110/500, Loss: 0.0305, Validation Loss: 0.0179\n",
            "Epoch 120/500, Loss: 0.0301, Validation Loss: 0.0167\n",
            "Epoch 130/500, Loss: 0.0298, Validation Loss: 0.0156\n",
            "Epoch 140/500, Loss: 0.0296, Validation Loss: 0.0147\n",
            "Epoch 150/500, Loss: 0.0293, Validation Loss: 0.0139\n",
            "Epoch 160/500, Loss: 0.0291, Validation Loss: 0.0132\n",
            "Epoch 170/500, Loss: 0.0290, Validation Loss: 0.0125\n",
            "Epoch 180/500, Loss: 0.0288, Validation Loss: 0.0119\n",
            "Epoch 190/500, Loss: 0.0286, Validation Loss: 0.0114\n",
            "Epoch 200/500, Loss: 0.0285, Validation Loss: 0.0109\n",
            "Epoch 210/500, Loss: 0.0284, Validation Loss: 0.0104\n",
            "Epoch 220/500, Loss: 0.0283, Validation Loss: 0.0099\n",
            "Epoch 230/500, Loss: 0.0280, Validation Loss: 0.0082\n",
            "Epoch 240/500, Loss: 0.0279, Validation Loss: 0.0078\n",
            "Epoch 250/500, Loss: 0.0278, Validation Loss: 0.0075\n",
            "Epoch 260/500, Loss: 0.0277, Validation Loss: 0.0072\n",
            "Epoch 270/500, Loss: 0.0276, Validation Loss: 0.0070\n",
            "Epoch 280/500, Loss: 0.0276, Validation Loss: 0.0067\n",
            "Epoch 290/500, Loss: 0.0275, Validation Loss: 0.0065\n",
            "Epoch 300/500, Loss: 0.0274, Validation Loss: 0.0063\n",
            "Epoch 310/500, Loss: 0.0274, Validation Loss: 0.0061\n",
            "Epoch 320/500, Loss: 0.0273, Validation Loss: 0.0060\n",
            "Epoch 330/500, Loss: 0.0273, Validation Loss: 0.0058\n",
            "Epoch 340/500, Loss: 0.0272, Validation Loss: 0.0056\n",
            "Epoch 350/500, Loss: 0.0272, Validation Loss: 0.0055\n",
            "Epoch 360/500, Loss: 0.0271, Validation Loss: 0.0054\n",
            "Epoch 370/500, Loss: 0.0271, Validation Loss: 0.0052\n",
            "Epoch 380/500, Loss: 0.0271, Validation Loss: 0.0051\n",
            "Epoch 390/500, Loss: 0.0270, Validation Loss: 0.0050\n",
            "Epoch 400/500, Loss: 0.0270, Validation Loss: 0.0049\n",
            "Epoch 410/500, Loss: 0.0270, Validation Loss: 0.0048\n",
            "Epoch 420/500, Loss: 0.0269, Validation Loss: 0.0047\n",
            "Epoch 430/500, Loss: 0.0269, Validation Loss: 0.0046\n",
            "Epoch 440/500, Loss: 0.0269, Validation Loss: 0.0045\n",
            "Epoch 450/500, Loss: 0.0268, Validation Loss: 0.0044\n",
            "Epoch 460/500, Loss: 0.0268, Validation Loss: 0.0043\n",
            "Epoch 470/500, Loss: 0.0268, Validation Loss: 0.0042\n",
            "Epoch 480/500, Loss: 0.0268, Validation Loss: 0.0042\n",
            "Epoch 490/500, Loss: 0.0267, Validation Loss: 0.0041\n",
            "Completeness: 0.5787149481121661\n",
            "Purity: 0.25807404489956676\n",
            "SNPCC Figure of Merit: 0.060128909815348734\n",
            "5\n",
            "Epoch 0/500, Loss: nan, Validation Loss: 21.1749\n",
            "Epoch 10/500, Loss: nan, Validation Loss: 4.8566\n",
            "Epoch 20/500, Loss: 1.8378, Validation Loss: 3.3720\n",
            "Epoch 30/500, Loss: 1.8938, Validation Loss: 2.6162\n",
            "Epoch 40/500, Loss: 1.2792, Validation Loss: 1.4224\n",
            "Epoch 50/500, Loss: 1.4632, Validation Loss: 1.1960\n",
            "Epoch 60/500, Loss: 1.2499, Validation Loss: 0.8224\n",
            "Epoch 70/500, Loss: 1.1892, Validation Loss: 0.6646\n",
            "Epoch 80/500, Loss: 0.8517, Validation Loss: 0.5544\n",
            "Epoch 90/500, Loss: 0.2625, Validation Loss: 0.1092\n",
            "Epoch 100/500, Loss: 0.2940, Validation Loss: 0.0914\n",
            "Epoch 110/500, Loss: 0.2864, Validation Loss: 0.1055\n",
            "Epoch 120/500, Loss: 0.7572, Validation Loss: 0.3792\n",
            "Epoch 130/500, Loss: 0.2723, Validation Loss: 0.0784\n",
            "Epoch 140/500, Loss: 0.2457, Validation Loss: 0.0745\n",
            "Epoch 150/500, Loss: 0.2467, Validation Loss: 0.0766\n",
            "Epoch 160/500, Loss: 0.2437, Validation Loss: 0.0721\n",
            "Epoch 170/500, Loss: 0.2443, Validation Loss: 0.0708\n",
            "Epoch 180/500, Loss: 0.3222, Validation Loss: 0.0664\n",
            "Epoch 190/500, Loss: 0.2614, Validation Loss: 0.0682\n",
            "Epoch 200/500, Loss: 0.2289, Validation Loss: 0.0693\n",
            "Epoch 210/500, Loss: 0.2315, Validation Loss: 0.0763\n",
            "Epoch 220/500, Loss: 0.2229, Validation Loss: 0.0741\n",
            "Epoch 230/500, Loss: 0.2115, Validation Loss: 0.0751\n",
            "Epoch 240/500, Loss: 0.2058, Validation Loss: 0.0744\n",
            "Epoch 250/500, Loss: 0.2048, Validation Loss: 0.0729\n",
            "Epoch 260/500, Loss: 0.1823, Validation Loss: 0.0766\n",
            "Epoch 270/500, Loss: 0.1746, Validation Loss: 0.0782\n",
            "Epoch 280/500, Loss: 0.1709, Validation Loss: 0.0791\n",
            "Epoch 290/500, Loss: 0.1644, Validation Loss: 0.0808\n",
            "Epoch 300/500, Loss: 0.1582, Validation Loss: 0.0828\n",
            "Epoch 310/500, Loss: 0.1540, Validation Loss: 0.0844\n",
            "Epoch 320/500, Loss: 0.1496, Validation Loss: 0.0864\n",
            "Epoch 330/500, Loss: 0.1464, Validation Loss: 0.0878\n",
            "Epoch 340/500, Loss: 0.1438, Validation Loss: 0.0889\n",
            "Epoch 350/500, Loss: 0.1415, Validation Loss: 0.0899\n",
            "Epoch 360/500, Loss: 0.1395, Validation Loss: 0.0908\n",
            "Epoch 370/500, Loss: 0.1376, Validation Loss: 0.0917\n",
            "Epoch 380/500, Loss: 0.1360, Validation Loss: 0.0924\n",
            "Epoch 390/500, Loss: 0.1344, Validation Loss: 0.0932\n",
            "Epoch 400/500, Loss: 0.1329, Validation Loss: 0.0940\n",
            "Epoch 410/500, Loss: 0.1315, Validation Loss: 0.0948\n",
            "Epoch 420/500, Loss: 0.1300, Validation Loss: 0.0958\n",
            "Epoch 430/500, Loss: 0.1287, Validation Loss: 0.0967\n",
            "Epoch 440/500, Loss: 0.1275, Validation Loss: 0.0974\n",
            "Epoch 450/500, Loss: 0.1264, Validation Loss: 0.0981\n",
            "Epoch 460/500, Loss: 0.1253, Validation Loss: 0.0988\n",
            "Epoch 470/500, Loss: 0.1243, Validation Loss: 0.0996\n",
            "Epoch 480/500, Loss: 0.1231, Validation Loss: 0.1006\n",
            "Epoch 490/500, Loss: 0.1217, Validation Loss: 0.1021\n",
            "Completeness: 0.6882313976595275\n",
            "Purity: 0.24483544104940697\n",
            "SNPCC Figure of Merit: 0.06712404225741567\n",
            "10\n",
            "Epoch 0/500, Loss: nan, Validation Loss: 10.3307\n",
            "Epoch 10/500, Loss: nan, Validation Loss: 1.9313\n",
            "Epoch 20/500, Loss: nan, Validation Loss: 1.2702\n",
            "Epoch 30/500, Loss: nan, Validation Loss: 1.0808\n",
            "Epoch 40/500, Loss: nan, Validation Loss: 1.7042\n",
            "Epoch 50/500, Loss: nan, Validation Loss: 1.1580\n",
            "Epoch 60/500, Loss: nan, Validation Loss: 0.8715\n",
            "Epoch 70/500, Loss: nan, Validation Loss: 0.8794\n",
            "Epoch 80/500, Loss: nan, Validation Loss: 0.5213\n",
            "Epoch 90/500, Loss: nan, Validation Loss: 0.2381\n",
            "Epoch 100/500, Loss: nan, Validation Loss: 0.2113\n",
            "Epoch 110/500, Loss: nan, Validation Loss: 0.2001\n",
            "Epoch 120/500, Loss: nan, Validation Loss: 0.2107\n",
            "Epoch 130/500, Loss: nan, Validation Loss: 0.2138\n",
            "Epoch 140/500, Loss: nan, Validation Loss: 0.2090\n",
            "Epoch 150/500, Loss: nan, Validation Loss: 0.1942\n",
            "Epoch 160/500, Loss: nan, Validation Loss: 0.1799\n",
            "Epoch 170/500, Loss: nan, Validation Loss: 0.1704\n",
            "Epoch 180/500, Loss: nan, Validation Loss: 0.1643\n",
            "Epoch 190/500, Loss: nan, Validation Loss: 0.1606\n",
            "Epoch 200/500, Loss: nan, Validation Loss: 0.1585\n",
            "Epoch 210/500, Loss: nan, Validation Loss: 0.1666\n",
            "Epoch 220/500, Loss: nan, Validation Loss: 0.1641\n",
            "Epoch 230/500, Loss: nan, Validation Loss: 0.1618\n",
            "Epoch 240/500, Loss: nan, Validation Loss: 0.1594\n",
            "Epoch 250/500, Loss: nan, Validation Loss: 0.1577\n",
            "Epoch 260/500, Loss: nan, Validation Loss: 0.1561\n",
            "Epoch 270/500, Loss: nan, Validation Loss: 0.1548\n",
            "Epoch 280/500, Loss: nan, Validation Loss: 0.1536\n",
            "Epoch 290/500, Loss: nan, Validation Loss: 0.1525\n",
            "Epoch 300/500, Loss: nan, Validation Loss: 0.1516\n",
            "Epoch 310/500, Loss: nan, Validation Loss: 0.1507\n",
            "Epoch 320/500, Loss: nan, Validation Loss: 0.1499\n",
            "Epoch 330/500, Loss: nan, Validation Loss: 0.1492\n",
            "Epoch 340/500, Loss: nan, Validation Loss: 0.1484\n",
            "Epoch 350/500, Loss: nan, Validation Loss: 0.1475\n",
            "Epoch 360/500, Loss: nan, Validation Loss: 0.1470\n",
            "Epoch 370/500, Loss: nan, Validation Loss: 0.1465\n",
            "Epoch 380/500, Loss: nan, Validation Loss: 0.1461\n",
            "Epoch 390/500, Loss: nan, Validation Loss: 0.1456\n",
            "Epoch 400/500, Loss: nan, Validation Loss: 0.1451\n",
            "Epoch 410/500, Loss: nan, Validation Loss: 0.1446\n",
            "Epoch 420/500, Loss: nan, Validation Loss: 0.1441\n",
            "Epoch 430/500, Loss: nan, Validation Loss: 0.1442\n",
            "Epoch 440/500, Loss: nan, Validation Loss: 0.1428\n",
            "Epoch 450/500, Loss: nan, Validation Loss: 0.1419\n",
            "Epoch 460/500, Loss: nan, Validation Loss: 0.1414\n",
            "Epoch 470/500, Loss: nan, Validation Loss: 0.1409\n",
            "Epoch 480/500, Loss: nan, Validation Loss: 0.1404\n",
            "Epoch 490/500, Loss: nan, Validation Loss: 0.1400\n",
            "Completeness: 0.5241775226319276\n",
            "Purity: 0.283259754205942\n",
            "SNPCC Figure of Merit: 0.061014829062426876\n",
            "20\n",
            "Epoch 0/500, Loss: 7.1099, Validation Loss: 5.9469\n",
            "Epoch 10/500, Loss: nan, Validation Loss: 2.0980\n",
            "Epoch 20/500, Loss: nan, Validation Loss: 2.8272\n",
            "Epoch 30/500, Loss: nan, Validation Loss: 1.6919\n",
            "Epoch 40/500, Loss: nan, Validation Loss: 0.7413\n",
            "Epoch 50/500, Loss: 0.7999, Validation Loss: 0.8226\n",
            "Epoch 60/500, Loss: 0.8079, Validation Loss: 0.5715\n",
            "Epoch 70/500, Loss: 0.5288, Validation Loss: 0.3045\n",
            "Epoch 80/500, Loss: 0.7893, Validation Loss: 0.6393\n",
            "Epoch 90/500, Loss: 0.5141, Validation Loss: 0.1307\n",
            "Epoch 100/500, Loss: 0.3590, Validation Loss: 0.0634\n",
            "Epoch 110/500, Loss: 0.3199, Validation Loss: 0.0630\n",
            "Epoch 120/500, Loss: 0.2802, Validation Loss: 0.0654\n",
            "Epoch 130/500, Loss: 0.2681, Validation Loss: 0.0573\n",
            "Epoch 140/500, Loss: 0.3125, Validation Loss: 0.0779\n",
            "Epoch 150/500, Loss: 0.3074, Validation Loss: 0.0457\n",
            "Epoch 160/500, Loss: 0.2479, Validation Loss: 0.1079\n",
            "Epoch 170/500, Loss: 0.2409, Validation Loss: 0.1199\n",
            "Epoch 180/500, Loss: 0.2372, Validation Loss: 0.1264\n",
            "Epoch 190/500, Loss: 0.2365, Validation Loss: 0.1337\n",
            "Epoch 200/500, Loss: 0.2318, Validation Loss: 0.1341\n",
            "Epoch 210/500, Loss: 0.2230, Validation Loss: 0.1302\n",
            "Epoch 220/500, Loss: 0.2082, Validation Loss: 0.1215\n",
            "Epoch 230/500, Loss: 0.1961, Validation Loss: 0.1146\n",
            "Epoch 240/500, Loss: 0.1949, Validation Loss: 0.1193\n",
            "Epoch 250/500, Loss: 0.1874, Validation Loss: 0.1178\n",
            "Epoch 260/500, Loss: 0.1754, Validation Loss: 0.1077\n",
            "Epoch 270/500, Loss: 0.1646, Validation Loss: 0.0968\n",
            "Epoch 280/500, Loss: 0.1571, Validation Loss: 0.0914\n",
            "Epoch 290/500, Loss: 0.1511, Validation Loss: 0.0862\n",
            "Epoch 300/500, Loss: 0.1458, Validation Loss: 0.0811\n",
            "Epoch 310/500, Loss: 0.1416, Validation Loss: 0.0774\n",
            "Epoch 320/500, Loss: 0.1387, Validation Loss: 0.0686\n",
            "Epoch 330/500, Loss: 0.1357, Validation Loss: 0.0545\n",
            "Epoch 340/500, Loss: 0.1308, Validation Loss: 0.0578\n",
            "Epoch 350/500, Loss: 0.1318, Validation Loss: 0.0557\n",
            "Epoch 360/500, Loss: 0.1272, Validation Loss: 0.0607\n",
            "Epoch 370/500, Loss: 0.1236, Validation Loss: 0.0563\n",
            "Epoch 380/500, Loss: 0.1208, Validation Loss: 0.0661\n",
            "Epoch 390/500, Loss: 0.1188, Validation Loss: 0.0552\n",
            "Epoch 400/500, Loss: 0.1165, Validation Loss: 0.0663\n",
            "Epoch 410/500, Loss: 0.1147, Validation Loss: 0.0545\n",
            "Epoch 420/500, Loss: 0.1132, Validation Loss: 0.0552\n",
            "Epoch 430/500, Loss: 0.1108, Validation Loss: 0.0551\n",
            "Epoch 440/500, Loss: 0.1092, Validation Loss: 0.0620\n",
            "Epoch 450/500, Loss: 0.1100, Validation Loss: 0.0648\n",
            "Epoch 460/500, Loss: 0.1084, Validation Loss: 0.0534\n",
            "Epoch 470/500, Loss: 0.1068, Validation Loss: 0.0513\n",
            "Epoch 480/500, Loss: 0.1048, Validation Loss: 0.0617\n",
            "Epoch 490/500, Loss: 0.1032, Validation Loss: 0.0532\n",
            "Completeness: 0.5345550894237139\n",
            "Purity: 0.29028776978417264\n",
            "SNPCC Figure of Merit: 0.06413707361952677\n",
            "30\n",
            "Epoch 0/500, Loss: nan, Validation Loss: nan\n",
            "Epoch 10/500, Loss: nan, Validation Loss: nan\n",
            "Epoch 20/500, Loss: nan, Validation Loss: nan\n",
            "Epoch 30/500, Loss: nan, Validation Loss: 3.4933\n",
            "Epoch 40/500, Loss: nan, Validation Loss: 2.1352\n",
            "Epoch 50/500, Loss: nan, Validation Loss: 3.2319\n",
            "Epoch 60/500, Loss: nan, Validation Loss: 2.2099\n",
            "Epoch 70/500, Loss: 0.9038, Validation Loss: 1.0463\n",
            "Epoch 80/500, Loss: 1.1946, Validation Loss: 1.9755\n",
            "Epoch 90/500, Loss: nan, Validation Loss: 1.9988\n",
            "Epoch 100/500, Loss: 0.9280, Validation Loss: 1.1384\n",
            "Epoch 110/500, Loss: 1.0567, Validation Loss: 1.0257\n",
            "Epoch 120/500, Loss: 0.7869, Validation Loss: 1.0627\n",
            "Epoch 130/500, Loss: nan, Validation Loss: 1.5018\n",
            "Epoch 140/500, Loss: nan, Validation Loss: 0.9341\n",
            "Epoch 150/500, Loss: nan, Validation Loss: 1.8227\n",
            "Epoch 160/500, Loss: nan, Validation Loss: 1.5765\n",
            "Epoch 170/500, Loss: nan, Validation Loss: 1.1046\n",
            "Epoch 180/500, Loss: 0.5301, Validation Loss: 0.6332\n",
            "Epoch 190/500, Loss: 0.5434, Validation Loss: 0.7707\n",
            "Epoch 200/500, Loss: 0.4453, Validation Loss: 0.6599\n",
            "Epoch 210/500, Loss: 0.4901, Validation Loss: 0.6499\n",
            "Epoch 220/500, Loss: nan, Validation Loss: 0.9790\n",
            "Epoch 230/500, Loss: nan, Validation Loss: 1.7879\n",
            "Epoch 240/500, Loss: 0.4801, Validation Loss: 0.5970\n",
            "Epoch 250/500, Loss: 0.4241, Validation Loss: 0.5453\n",
            "Epoch 260/500, Loss: 0.3444, Validation Loss: 0.4642\n",
            "Epoch 270/500, Loss: 0.3014, Validation Loss: 0.3641\n",
            "Epoch 280/500, Loss: 0.2552, Validation Loss: 0.2608\n",
            "Epoch 290/500, Loss: 0.2375, Validation Loss: 0.2419\n",
            "Epoch 300/500, Loss: 0.2263, Validation Loss: 0.2644\n",
            "Epoch 310/500, Loss: 0.2428, Validation Loss: 0.3026\n",
            "Epoch 320/500, Loss: 0.2232, Validation Loss: 0.2364\n",
            "Epoch 330/500, Loss: 0.1978, Validation Loss: 0.2068\n",
            "Epoch 340/500, Loss: 0.1905, Validation Loss: 0.2006\n",
            "Epoch 350/500, Loss: 0.1844, Validation Loss: 0.1985\n",
            "Epoch 360/500, Loss: 0.1797, Validation Loss: 0.1966\n",
            "Epoch 370/500, Loss: 0.1754, Validation Loss: 0.1968\n",
            "Epoch 380/500, Loss: 0.1707, Validation Loss: 0.1889\n",
            "Epoch 390/500, Loss: 0.1657, Validation Loss: 0.1862\n",
            "Epoch 400/500, Loss: 0.1614, Validation Loss: 0.1835\n",
            "Epoch 410/500, Loss: 0.1572, Validation Loss: 0.1904\n",
            "Epoch 420/500, Loss: 0.1491, Validation Loss: 0.1777\n",
            "Epoch 430/500, Loss: 0.1450, Validation Loss: 0.1754\n",
            "Epoch 440/500, Loss: 0.1400, Validation Loss: 0.1749\n",
            "Epoch 450/500, Loss: 0.1366, Validation Loss: 0.1719\n",
            "Epoch 460/500, Loss: 0.1336, Validation Loss: 0.1718\n",
            "Epoch 470/500, Loss: 0.1316, Validation Loss: 0.1766\n",
            "Epoch 480/500, Loss: 0.1289, Validation Loss: 0.1730\n",
            "Epoch 490/500, Loss: 0.1261, Validation Loss: 0.1750\n",
            "Completeness: 0.6001324795760653\n",
            "Purity: 0.30498204667863554\n",
            "SNPCC Figure of Merit: 0.0765802854219599\n",
            "40\n",
            "Epoch 0/500, Loss: nan, Validation Loss: nan\n",
            "Epoch 10/500, Loss: inf, Validation Loss: 1.5095\n",
            "Epoch 20/500, Loss: inf, Validation Loss: nan\n",
            "Epoch 30/500, Loss: inf, Validation Loss: nan\n",
            "Epoch 40/500, Loss: inf, Validation Loss: nan\n",
            "Epoch 50/500, Loss: inf, Validation Loss: nan\n",
            "Epoch 60/500, Loss: inf, Validation Loss: nan\n",
            "Epoch 70/500, Loss: inf, Validation Loss: nan\n",
            "Epoch 80/500, Loss: inf, Validation Loss: nan\n",
            "Epoch 90/500, Loss: 1.5700, Validation Loss: nan\n",
            "Epoch 100/500, Loss: 1.3707, Validation Loss: nan\n",
            "Epoch 110/500, Loss: 1.1963, Validation Loss: nan\n",
            "Epoch 120/500, Loss: 1.1806, Validation Loss: nan\n",
            "Epoch 130/500, Loss: 1.6104, Validation Loss: nan\n",
            "Epoch 140/500, Loss: 0.8617, Validation Loss: nan\n",
            "Epoch 150/500, Loss: 0.8710, Validation Loss: nan\n",
            "Epoch 160/500, Loss: 0.7125, Validation Loss: nan\n",
            "Epoch 170/500, Loss: 0.6162, Validation Loss: nan\n",
            "Epoch 180/500, Loss: 0.6758, Validation Loss: nan\n",
            "Epoch 190/500, Loss: 1.8949, Validation Loss: nan\n",
            "Epoch 200/500, Loss: 1.0365, Validation Loss: nan\n",
            "Epoch 210/500, Loss: 0.7076, Validation Loss: nan\n",
            "Epoch 220/500, Loss: 0.5737, Validation Loss: nan\n",
            "Epoch 230/500, Loss: 0.4357, Validation Loss: nan\n",
            "Epoch 240/500, Loss: 0.3252, Validation Loss: 0.1414\n",
            "Epoch 250/500, Loss: 0.3317, Validation Loss: 0.1301\n",
            "Epoch 260/500, Loss: 0.3188, Validation Loss: 0.1300\n",
            "Epoch 270/500, Loss: 0.3039, Validation Loss: 0.1170\n",
            "Epoch 280/500, Loss: 0.2801, Validation Loss: 0.1125\n",
            "Epoch 290/500, Loss: 0.2800, Validation Loss: 0.1122\n",
            "Epoch 300/500, Loss: 0.2647, Validation Loss: 0.1064\n",
            "Epoch 310/500, Loss: 0.2603, Validation Loss: 0.1016\n",
            "Epoch 320/500, Loss: 0.2361, Validation Loss: 0.0944\n",
            "Epoch 330/500, Loss: 0.2198, Validation Loss: 0.0905\n",
            "Epoch 340/500, Loss: 0.2159, Validation Loss: 0.0891\n",
            "Epoch 350/500, Loss: 0.2038, Validation Loss: 0.0849\n",
            "Epoch 360/500, Loss: 0.1973, Validation Loss: 0.0826\n",
            "Epoch 370/500, Loss: 0.1925, Validation Loss: 0.0806\n",
            "Epoch 380/500, Loss: 0.1914, Validation Loss: 0.0803\n",
            "Epoch 390/500, Loss: 0.1818, Validation Loss: 0.0766\n",
            "Epoch 400/500, Loss: 0.1755, Validation Loss: 0.0754\n",
            "Epoch 410/500, Loss: 0.1709, Validation Loss: 0.0742\n",
            "Epoch 420/500, Loss: 0.1647, Validation Loss: 0.0725\n",
            "Epoch 430/500, Loss: 0.1606, Validation Loss: 0.0709\n",
            "Epoch 440/500, Loss: 0.1580, Validation Loss: 0.0707\n",
            "Epoch 450/500, Loss: 0.1553, Validation Loss: 0.0699\n",
            "Epoch 460/500, Loss: 0.1522, Validation Loss: 0.0693\n",
            "Epoch 470/500, Loss: 0.1499, Validation Loss: 0.0678\n",
            "Epoch 480/500, Loss: 0.1476, Validation Loss: 0.0677\n",
            "Epoch 490/500, Loss: 0.1462, Validation Loss: 0.0674\n",
            "Completeness: 0.5877677191432987\n",
            "Purity: 0.28295068027210885\n",
            "SNPCC Figure of Merit: 0.06832478901133018\n",
            "50\n",
            "Epoch 0/500, Loss: nan, Validation Loss: 18.7647\n",
            "Epoch 10/500, Loss: nan, Validation Loss: 7.0288\n",
            "Epoch 20/500, Loss: nan, Validation Loss: 3.3089\n",
            "Epoch 30/500, Loss: nan, Validation Loss: 3.5411\n",
            "Epoch 40/500, Loss: nan, Validation Loss: 3.1521\n",
            "Epoch 50/500, Loss: nan, Validation Loss: 2.8393\n",
            "Epoch 60/500, Loss: nan, Validation Loss: 3.1333\n",
            "Epoch 70/500, Loss: nan, Validation Loss: 2.2596\n",
            "Epoch 80/500, Loss: nan, Validation Loss: 1.8140\n",
            "Epoch 90/500, Loss: nan, Validation Loss: 3.1743\n",
            "Epoch 100/500, Loss: nan, Validation Loss: 1.9032\n",
            "Epoch 110/500, Loss: nan, Validation Loss: 1.6193\n",
            "Epoch 120/500, Loss: nan, Validation Loss: 1.9876\n",
            "Epoch 130/500, Loss: nan, Validation Loss: 2.3932\n",
            "Epoch 140/500, Loss: nan, Validation Loss: 1.8673\n",
            "Epoch 150/500, Loss: nan, Validation Loss: 2.0113\n",
            "Epoch 160/500, Loss: nan, Validation Loss: 1.9810\n",
            "Epoch 170/500, Loss: nan, Validation Loss: 1.9794\n",
            "Epoch 180/500, Loss: nan, Validation Loss: 2.4926\n",
            "Epoch 190/500, Loss: nan, Validation Loss: 1.7252\n",
            "Epoch 200/500, Loss: nan, Validation Loss: 1.8762\n",
            "Epoch 210/500, Loss: nan, Validation Loss: 2.0333\n",
            "Epoch 220/500, Loss: nan, Validation Loss: 2.0853\n",
            "Epoch 230/500, Loss: nan, Validation Loss: 1.3144\n",
            "Epoch 240/500, Loss: nan, Validation Loss: 1.8284\n",
            "Epoch 250/500, Loss: nan, Validation Loss: 1.1900\n",
            "Epoch 260/500, Loss: nan, Validation Loss: 1.7652\n",
            "Epoch 270/500, Loss: nan, Validation Loss: 1.2647\n",
            "Epoch 280/500, Loss: nan, Validation Loss: 0.9812\n",
            "Epoch 290/500, Loss: nan, Validation Loss: 1.1232\n",
            "Epoch 300/500, Loss: nan, Validation Loss: 0.9961\n",
            "Epoch 310/500, Loss: nan, Validation Loss: 0.8698\n",
            "Epoch 320/500, Loss: nan, Validation Loss: 0.8860\n",
            "Epoch 330/500, Loss: nan, Validation Loss: 0.8366\n",
            "Epoch 340/500, Loss: nan, Validation Loss: 1.1930\n",
            "Epoch 350/500, Loss: nan, Validation Loss: 1.2673\n",
            "Epoch 360/500, Loss: nan, Validation Loss: 1.5110\n",
            "Epoch 370/500, Loss: nan, Validation Loss: 1.3343\n",
            "Epoch 380/500, Loss: nan, Validation Loss: 1.2411\n",
            "Epoch 390/500, Loss: 0.6636, Validation Loss: 1.0524\n",
            "Epoch 400/500, Loss: nan, Validation Loss: 1.8503\n",
            "Epoch 410/500, Loss: 0.6110, Validation Loss: 0.9891\n",
            "Epoch 420/500, Loss: 0.5485, Validation Loss: 0.9923\n",
            "Epoch 430/500, Loss: 0.6187, Validation Loss: 0.9432\n",
            "Epoch 440/500, Loss: 0.5243, Validation Loss: 0.8550\n",
            "Epoch 450/500, Loss: 0.3885, Validation Loss: 0.7648\n",
            "Epoch 460/500, Loss: nan, Validation Loss: 3.4046\n",
            "Epoch 470/500, Loss: nan, Validation Loss: 2.2190\n",
            "Epoch 480/500, Loss: 0.7366, Validation Loss: 1.2049\n",
            "Epoch 490/500, Loss: 0.5469, Validation Loss: 0.8333\n",
            "Completeness: 0.7701479355266063\n",
            "Purity: 0.27466729663753053\n",
            "SNPCC Figure of Merit: 0.08631714916348456\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = pd.DataFrame(columns=['Sample Size','Z Used','COMPLENETENESS','PURITY','FOM','name'])"
      ],
      "metadata": {
        "id": "8qL1G1hFk6IN"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['d0','d1','d2','d3','d4','d5','S']"
      ],
      "metadata": {
        "id": "9KPCJbx0c6Yz"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res['Sample Size'] = GLOBAL_SAMPLE_SIZE\n",
        "res['Z Used'] = GLOBAL_Z_USED\n",
        "res['COMPLENETENESS'] = GLOBAL_COMPLETENESS\n",
        "res['PURITY'] = GLOBAL_PURITY\n",
        "res['FOM'] = GLOBAL_FOM\n",
        "res['name'] = names*2"
      ],
      "metadata": {
        "id": "Lh6TKr6ElbEt"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "SpbhbMIRljqH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "138cbd50-b774-4287-b43c-a581ef56bef3"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sample Size Z Used  COMPLENETENESS    PURITY       FOM name\n",
              "0             5     no        0.675867  0.250163  0.067640   d0\n",
              "1            10     no        0.743873  0.235348  0.069216   d1\n",
              "2            20     no        0.578494  0.280815  0.066622   d2\n",
              "3            30     no        0.833297  0.248994  0.082928   d3\n",
              "4            40     no        0.476706  0.298040  0.059102   d4\n",
              "5            50     no        0.860234  0.244034  0.083572   d5\n",
              "6           100     no        0.909251  0.243683  0.088182    S\n",
              "7             5    yes        0.578715  0.258074  0.060129   d0\n",
              "8            10    yes        0.688231  0.244835  0.067124   d1\n",
              "9            20    yes        0.524178  0.283260  0.061015   d2\n",
              "10           30    yes        0.534555  0.290288  0.064137   d3\n",
              "11           40    yes        0.600132  0.304982  0.076580   d4\n",
              "12           50    yes        0.587768  0.282951  0.068325   d5\n",
              "13          100    yes        0.770148  0.274667  0.086317    S"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d5b71e4-6b4a-4dfd-9a4b-2873c4231151\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sample Size</th>\n",
              "      <th>Z Used</th>\n",
              "      <th>COMPLENETENESS</th>\n",
              "      <th>PURITY</th>\n",
              "      <th>FOM</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>no</td>\n",
              "      <td>0.675867</td>\n",
              "      <td>0.250163</td>\n",
              "      <td>0.067640</td>\n",
              "      <td>d0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>no</td>\n",
              "      <td>0.743873</td>\n",
              "      <td>0.235348</td>\n",
              "      <td>0.069216</td>\n",
              "      <td>d1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>no</td>\n",
              "      <td>0.578494</td>\n",
              "      <td>0.280815</td>\n",
              "      <td>0.066622</td>\n",
              "      <td>d2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>no</td>\n",
              "      <td>0.833297</td>\n",
              "      <td>0.248994</td>\n",
              "      <td>0.082928</td>\n",
              "      <td>d3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40</td>\n",
              "      <td>no</td>\n",
              "      <td>0.476706</td>\n",
              "      <td>0.298040</td>\n",
              "      <td>0.059102</td>\n",
              "      <td>d4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>50</td>\n",
              "      <td>no</td>\n",
              "      <td>0.860234</td>\n",
              "      <td>0.244034</td>\n",
              "      <td>0.083572</td>\n",
              "      <td>d5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>100</td>\n",
              "      <td>no</td>\n",
              "      <td>0.909251</td>\n",
              "      <td>0.243683</td>\n",
              "      <td>0.088182</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.578715</td>\n",
              "      <td>0.258074</td>\n",
              "      <td>0.060129</td>\n",
              "      <td>d0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.688231</td>\n",
              "      <td>0.244835</td>\n",
              "      <td>0.067124</td>\n",
              "      <td>d1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.524178</td>\n",
              "      <td>0.283260</td>\n",
              "      <td>0.061015</td>\n",
              "      <td>d2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>30</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.534555</td>\n",
              "      <td>0.290288</td>\n",
              "      <td>0.064137</td>\n",
              "      <td>d3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>40</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.600132</td>\n",
              "      <td>0.304982</td>\n",
              "      <td>0.076580</td>\n",
              "      <td>d4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>50</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.587768</td>\n",
              "      <td>0.282951</td>\n",
              "      <td>0.068325</td>\n",
              "      <td>d5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>100</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.770148</td>\n",
              "      <td>0.274667</td>\n",
              "      <td>0.086317</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d5b71e4-6b4a-4dfd-9a4b-2873c4231151')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1d5b71e4-6b4a-4dfd-9a4b-2873c4231151 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1d5b71e4-6b4a-4dfd-9a4b-2873c4231151');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1b2aa275-c787-4625-a47a-a93287d30faf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b2aa275-c787-4625-a47a-a93287d30faf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1b2aa275-c787-4625-a47a-a93287d30faf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_55042808-8d51-4280-9e5b-7ad836721b90\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('res')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_55042808-8d51-4280-9e5b-7ad836721b90 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('res');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMDjgVot9xW/qSq8XcOzRrs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}