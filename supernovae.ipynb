{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/canoztas/CMP684-Neural-Networks-supernovae/blob/main/supernovae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqmyni5GYzPJ",
        "outputId": "e03a906d-a70f-4687-a41f-4683d7c5cc18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lqpPYVuQ9_PQ"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wkuRQB-bKN6x"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def read_data(filename): #Read data from a pickled file to a pandas DataFrame.\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    X = to_dataframe(data)\n",
        "    y = pd.get_dummies(X['type'] == 0, prefix='SNIa', drop_first=True)\n",
        "    X = X.drop(columns=['comment', 'type'])\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def to_dataframe(data): #Converts from a Python dictionary to a pandas DataFrame.\n",
        "    for idx, sn in data.items():\n",
        "        for filt in 'griz':\n",
        "            sn[f'mjd_{filt}'] = np.array(sn[filt]['mjd'])\n",
        "            sn[f'fluxcal_{filt}'] = np.array(sn[filt]['fluxcal'])\n",
        "            sn[f'fluxcalerr_{filt}'] = np.array(sn[filt]['fluxcalerr'])\n",
        "            del sn[filt]\n",
        "        sn.update(sn['header'])\n",
        "        del sn['header']\n",
        "\n",
        "    return pd.DataFrame.from_dict(data, orient='index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "gvLV9hz1WBGR"
      },
      "outputs": [],
      "source": [
        "X_train_raw, y_train = read_data('/content/drive/MyDrive/dataset/neuralnetwork/des_train.pkl')\n",
        "X_test_raw, y_test = read_data('/content/drive/MyDrive/dataset/neuralnetwork/des_test.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IvOaiUElIvva"
      },
      "outputs": [],
      "source": [
        "def bazin(time, A, B, t0, tfall, trise):\n",
        "    X = np.exp(-(time - t0) / tfall) / (1 + np.exp((time - t0) / trise))\n",
        "    return A * X + B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Qafek9U2IyGW"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize import least_squares\n",
        "\n",
        "def lightcurve_fit(time, flux):\n",
        "    scaled_time = time - time.min()\n",
        "    t0 = scaled_time[flux.argmax()]\n",
        "    guess = (0, 0, t0, 40, -5)\n",
        "\n",
        "    errfunc = lambda params: abs(flux - bazin(scaled_time, *params))\n",
        "\n",
        "    result = least_squares(errfunc, guess, method='lm')\n",
        "\n",
        "    return result.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SEw_3Q_-I0xv"
      },
      "outputs": [],
      "source": [
        "def uncertain_mean(flux, flux_err, w):\n",
        "    UM = [x / y if y != 0 else x for x, y in zip(flux, flux_err)]\n",
        "\n",
        "    if w != 0:\n",
        "        return sum(UM) / w\n",
        "    return sum(UM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VX5NO9dXI3Di"
      },
      "outputs": [],
      "source": [
        "def uncertain_moving_average(flux, flux_err, w):\n",
        "    l = len(flux)\n",
        "    UMA = []\n",
        "\n",
        "    if l <= 2 * w:\n",
        "        UMA = flux\n",
        "    else:\n",
        "        for i in range(l):\n",
        "            if i <= l - w:\n",
        "                um = uncertain_mean(flux[i:i + w], flux_err[i:i + w], w)\n",
        "            else:\n",
        "                um = uncertain_mean(flux[i:l], flux_err[i:l], l - i)\n",
        "\n",
        "            UMA.append(um)\n",
        "\n",
        "    return UMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-_HpmhOqI5QH"
      },
      "outputs": [],
      "source": [
        "def znormalization(UMA):\n",
        "    array_UMA = np.array(UMA)\n",
        "    m = np.mean(array_UMA)\n",
        "    std = np.std(array_UMA)\n",
        "    zUMA = [(x - m)/std  for x in UMA]\n",
        "    return zUMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jPgmc3ilJBNj"
      },
      "outputs": [],
      "source": [
        "def preprocessing(data):\n",
        "    #Window length for computing uncertain moving average filtering\n",
        "    w = 10\n",
        "    DES_FILTERS = 'griz'\n",
        "    # Create palceholder for output matrix\n",
        "    full_params = np.zeros((len(data), 5 * len(DES_FILTERS)))\n",
        "    # Iterate over supernovae\n",
        "    for idx, snid in enumerate(data.index):\n",
        "        params = np.zeros((len(DES_FILTERS), 5))\n",
        "        # Iterate over filters\n",
        "        for id_f, f in enumerate(DES_FILTERS):\n",
        "            time = data.loc[snid, 'mjd_%s' % f]\n",
        "            flux = data.loc[snid, 'fluxcal_%s' % f]\n",
        "            flux_err = data.loc[snid, 'fluxcalerr_%s' % f]\n",
        "\n",
        "            flux_uma = uncertain_moving_average(flux, flux_err, w)\n",
        "            flux_zuma = znormalization(flux_uma)\n",
        "            flux_zuma = np.array(flux_zuma)\n",
        "            try:\n",
        "                params[id_f] = lightcurve_fit(time,  flux_zuma)\n",
        "            except ValueError:\n",
        "                # If fit does not converge leave zeros\n",
        "                continue\n",
        "        full_params[idx] = params.ravel()\n",
        "\n",
        "    return full_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "W5BwvZK4JDWA"
      },
      "outputs": [],
      "source": [
        "X_train = preprocessing(X_train_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "ZHc9_lFW_nVo"
      },
      "outputs": [],
      "source": [
        "X_test = preprocessing(X_test_raw)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.to_numpy()"
      ],
      "metadata": {
        "id": "XF4BC7wpdsLE"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = y_test.to_numpy()"
      ],
      "metadata": {
        "id": "8Kfid6-hdwTc"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OEEERcT29C5m"
      },
      "outputs": [],
      "source": [
        "# Sigmoid and tanh activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "IhrT-LAG9Hy0"
      },
      "outputs": [],
      "source": [
        "def neural_network(isZincluded,epoch,lr,X_train,y_train,X_test):\n",
        "  # Assuming 4 filters (g, r, i, z) are used in the light curve. If used input size = 20 if not input size = 16\n",
        "  input_size = 14\n",
        "  if isZincluded:\n",
        "    input_size = 20\n",
        "\n",
        "  # Initialize weights and biases for the hidden layer\n",
        "  hidden_weights = np.random.randn(input_size, 500)\n",
        "  hidden_biases = np.zeros((1, 500))\n",
        "\n",
        "  # Initialize weights and biases for the output layer\n",
        "  output_weights = np.random.randn(500, 1)\n",
        "  output_biases = np.zeros((1, 1))\n",
        "\n",
        "  # Training parameters\n",
        "  learning_rate = lr\n",
        "  epochs = epoch\n",
        "  batch_size = 16\n",
        "  validation_split = 0.1\n",
        "  start_training(X_train,y_train,epoch,lr,validation_split,hidden_weights,hidden_biases,output_weights,output_biases,X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gZYgURnR9LF4"
      },
      "outputs": [],
      "source": [
        "def start_training(X_train,y_train,epochs,learning_rate,validation_split,hidden_weights,hidden_biases,output_weights,output_biases,X_test):\n",
        "  # Training loop\n",
        "  for epoch in range(epochs):\n",
        "      # Forward pass\n",
        "      hidden_layer_input = np.dot(X_train, hidden_weights) + hidden_biases\n",
        "      hidden_layer_output = tanh(hidden_layer_input)\n",
        "\n",
        "      output_layer_input = np.dot(hidden_layer_output, output_weights) + output_biases\n",
        "      output_layer_output = sigmoid(output_layer_input)\n",
        "\n",
        "      # Compute loss (assuming binary cross-entropy)\n",
        "      loss = -np.mean(y_train * np.log(output_layer_output) + (1 - y_train) * np.log(1 - output_layer_output))\n",
        "\n",
        "      # Backward pass\n",
        "      output_error = output_layer_output - y_train\n",
        "      hidden_error = np.dot(output_error, output_weights.T) * (1 - np.square(hidden_layer_output))\n",
        "\n",
        "      # Update weights and biases\n",
        "      output_weights -= learning_rate * np.dot(hidden_layer_output.T, output_error) / len(X_train)\n",
        "      output_biases -= learning_rate * np.sum(output_error, axis=0, keepdims=True) / len(X_train)\n",
        "\n",
        "      hidden_weights -= learning_rate * np.dot(X_train.T, hidden_error) / len(X_train)\n",
        "      hidden_biases -= learning_rate * np.sum(hidden_error, axis=0, keepdims=True) / len(X_train)\n",
        "\n",
        "      # Validation loss\n",
        "      if epoch % 100 == 0:\n",
        "          val_hidden_layer_output = tanh(np.dot(X_train[int(X_train.shape[0] * (1 - validation_split)):], hidden_weights) + hidden_biases)\n",
        "          val_output_layer_output = sigmoid(np.dot(val_hidden_layer_output, output_weights) + output_biases)\n",
        "          val_loss = -np.mean(y_train[int(X_train.shape[0] * (1 - validation_split)):] * np.log(val_output_layer_output) +\n",
        "                              (1 - y_train[int(X_train.shape[0] * (1 - validation_split)):]) * np.log(1 - val_output_layer_output))\n",
        "          print(f\"Epoch {epoch}/{epochs}, Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "  prediction(hidden_weights,hidden_biases,output_weights,output_biases,X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JlJNJYC2-EPh"
      },
      "outputs": [],
      "source": [
        "def prediction(hidden_weights,hidden_biases,output_weights,output_biases,X_test):\n",
        "  # Prediction\n",
        "  test_hidden_layer_output = tanh(np.dot(X_test, hidden_weights) + hidden_biases)\n",
        "  y_pred = sigmoid(np.dot(test_hidden_layer_output, output_weights) + output_biases)\n",
        "  calculate_results(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "rbM5PfqIFUxO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def calculate_metrics(true_labels, predicted_probs, threshold=0.5, penalty_factor=3):\n",
        "    # Convert probabilities to class labels based on the threshold\n",
        "    predicted_labels = (predicted_probs > threshold).astype(int)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "    # Extract values from the confusion matrix\n",
        "    N_total_Ia = cm[1, :].sum()\n",
        "    N_true_Ia = cm[1, 1]\n",
        "    N_false_Ia = cm[0, 1]\n",
        "\n",
        "    # Completeness\n",
        "    completeness_Ia = N_true_Ia / N_total_Ia\n",
        "\n",
        "    # Purity\n",
        "    purity_Ia = N_true_Ia / (N_true_Ia + N_false_Ia)\n",
        "\n",
        "    # SNPCC Figure of Merit\n",
        "    FIa = (N_true_Ia ** 2) / (N_total_Ia * (N_true_Ia + penalty_factor * N_false_Ia))\n",
        "\n",
        "    return completeness_Ia, purity_Ia, FIa\n",
        "\n",
        "def calculate_results(y_pred):\n",
        "  true_labels = y_test\n",
        "  predicted_probs = y_pred\n",
        "\n",
        "  threshold = 0.5\n",
        "  penalty_factor = 3\n",
        "\n",
        "  completeness, purity, figure_of_merit = calculate_metrics(true_labels, predicted_probs, threshold, penalty_factor)\n",
        "\n",
        "  print(\"Completeness:\", completeness)\n",
        "  GLOBAL_COMPLETENESS.append(completeness)\n",
        "  print(\"Purity:\", purity)\n",
        "  GLOBAL_PURITY.append(purity)\n",
        "  print(\"SNPCC Figure of Merit:\", figure_of_merit)\n",
        "  GLOBAL_FOM.append(figure_of_merit)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GLOBAL_SAMPLE_SIZE = []\n",
        "GLOBAL_Z_USED = []\n",
        "GLOBAL_COMPLETENESS = []\n",
        "GLOBAL_PURITY = []\n",
        "GLOBAL_FOM = []"
      ],
      "metadata": {
        "id": "-Uvtzft0K3Nu"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of elements to select\n",
        "percentages = [5,10,20,30,40,50,100]\n",
        "for percentage in percentages:\n",
        "  num_elements_to_select = int(len(X_train) * (percentage / 100.0))\n",
        "\n",
        "  # Use numpy.random.choice to get random indices\n",
        "  random_indices = np.random.choice(len(X_train), size=num_elements_to_select, replace=False)\n",
        "\n",
        "  # Get the selected elements from the original array\n",
        "  X_train_local = X_train[random_indices]\n",
        "  tmp = pd.DataFrame(X_train_local).iloc[:,:9]\n",
        "  tmp = tmp.join(pd.DataFrame(X_train_local).iloc[:,12])\n",
        "  tmp = tmp.join(pd.DataFrame(X_train_local).iloc[:,14:18])\n",
        "  X_train_local = tmp.to_numpy()\n",
        "\n",
        "  y_train_local = y_train[random_indices]\n",
        "\n",
        "  X_test_local = X_test\n",
        "  tmp = pd.DataFrame(X_test_local).iloc[:,:9]\n",
        "  tmp = tmp.join(pd.DataFrame(X_test_local).iloc[:,12])\n",
        "  tmp = tmp.join(pd.DataFrame(X_test_local).iloc[:,14:18])\n",
        "  X_test_local = tmp.to_numpy()\n",
        "\n",
        "  GLOBAL_SAMPLE_SIZE.append(percentage)\n",
        "  GLOBAL_Z_USED.append('no')\n",
        "  neural_network(False,5000,0.1,X_train_local,y_train_local,X_test_local)\n",
        "  print(percentage)"
      ],
      "metadata": {
        "id": "X81wEO5tjU44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03aff899-d020-47f9-e668-4bc047196fc5"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/5000, Loss: nan, Validation Loss: 1.7800\n",
            "Epoch 100/5000, Loss: 0.1466, Validation Loss: 0.0003\n",
            "Epoch 200/5000, Loss: 0.0991, Validation Loss: 0.0003\n",
            "Epoch 300/5000, Loss: 0.0865, Validation Loss: 0.0002\n",
            "Epoch 400/5000, Loss: 0.0785, Validation Loss: 0.0001\n",
            "Epoch 500/5000, Loss: 0.0728, Validation Loss: 0.0001\n",
            "Epoch 600/5000, Loss: 0.0684, Validation Loss: 0.0001\n",
            "Epoch 700/5000, Loss: 0.0648, Validation Loss: 0.0001\n",
            "Epoch 800/5000, Loss: 0.0618, Validation Loss: 0.0001\n",
            "Epoch 900/5000, Loss: 0.0593, Validation Loss: 0.0001\n",
            "Epoch 1000/5000, Loss: 0.0573, Validation Loss: 0.0001\n",
            "Epoch 1100/5000, Loss: 0.0557, Validation Loss: 0.0001\n",
            "Epoch 1200/5000, Loss: 0.0541, Validation Loss: 0.0001\n",
            "Epoch 1300/5000, Loss: 0.0527, Validation Loss: 0.0001\n",
            "Epoch 1400/5000, Loss: 0.0515, Validation Loss: 0.0001\n",
            "Epoch 1500/5000, Loss: 0.0505, Validation Loss: 0.0001\n",
            "Epoch 1600/5000, Loss: 0.0495, Validation Loss: 0.0001\n",
            "Epoch 1700/5000, Loss: 0.0487, Validation Loss: 0.0001\n",
            "Epoch 1800/5000, Loss: 0.0479, Validation Loss: 0.0001\n",
            "Epoch 1900/5000, Loss: 0.0473, Validation Loss: 0.0001\n",
            "Epoch 2000/5000, Loss: 0.0467, Validation Loss: 0.0001\n",
            "Epoch 2100/5000, Loss: 0.0461, Validation Loss: 0.0001\n",
            "Epoch 2200/5000, Loss: 0.0456, Validation Loss: 0.0001\n",
            "Epoch 2300/5000, Loss: 0.0451, Validation Loss: 0.0001\n",
            "Epoch 2400/5000, Loss: 0.0447, Validation Loss: 0.0001\n",
            "Epoch 2500/5000, Loss: 0.0443, Validation Loss: 0.0001\n",
            "Epoch 2600/5000, Loss: 0.0439, Validation Loss: 0.0001\n",
            "Epoch 2700/5000, Loss: 0.0436, Validation Loss: 0.0001\n",
            "Epoch 2800/5000, Loss: 0.0433, Validation Loss: 0.0001\n",
            "Epoch 2900/5000, Loss: 0.0430, Validation Loss: 0.0001\n",
            "Epoch 3000/5000, Loss: 0.0427, Validation Loss: 0.0000\n",
            "Epoch 3100/5000, Loss: 0.0424, Validation Loss: 0.0000\n",
            "Epoch 3200/5000, Loss: 0.0422, Validation Loss: 0.0000\n",
            "Epoch 3300/5000, Loss: 0.0419, Validation Loss: 0.0000\n",
            "Epoch 3400/5000, Loss: 0.0417, Validation Loss: 0.0000\n",
            "Epoch 3500/5000, Loss: 0.0415, Validation Loss: 0.0000\n",
            "Epoch 3600/5000, Loss: 0.0413, Validation Loss: 0.0000\n",
            "Epoch 3700/5000, Loss: 0.0412, Validation Loss: 0.0000\n",
            "Epoch 3800/5000, Loss: 0.0410, Validation Loss: 0.0000\n",
            "Epoch 3900/5000, Loss: 0.0408, Validation Loss: 0.0000\n",
            "Epoch 4000/5000, Loss: 0.0407, Validation Loss: 0.0000\n",
            "Epoch 4100/5000, Loss: 0.0405, Validation Loss: 0.0000\n",
            "Epoch 4200/5000, Loss: 0.0404, Validation Loss: 0.0000\n",
            "Epoch 4300/5000, Loss: 0.0402, Validation Loss: 0.0000\n",
            "Epoch 4400/5000, Loss: 0.0401, Validation Loss: 0.0000\n",
            "Epoch 4500/5000, Loss: 0.0400, Validation Loss: 0.0000\n",
            "Epoch 4600/5000, Loss: 0.0399, Validation Loss: 0.0000\n",
            "Epoch 4700/5000, Loss: 0.0398, Validation Loss: 0.0000\n",
            "Epoch 4800/5000, Loss: 0.0396, Validation Loss: 0.0000\n",
            "Epoch 4900/5000, Loss: 0.0395, Validation Loss: 0.0000\n",
            "Completeness: 0.5780525502318392\n",
            "Purity: 0.24881201292529936\n",
            "SNPCC Figure of Merit: 0.057475942898099326\n",
            "5\n",
            "Epoch 0/5000, Loss: inf, Validation Loss: 2.8994\n",
            "Epoch 100/5000, Loss: 0.0520, Validation Loss: 0.0175\n",
            "Epoch 200/5000, Loss: 0.0348, Validation Loss: 0.0105\n",
            "Epoch 300/5000, Loss: 0.0302, Validation Loss: 0.0089\n",
            "Epoch 400/5000, Loss: 0.0276, Validation Loss: 0.0083\n",
            "Epoch 500/5000, Loss: 0.0254, Validation Loss: 0.0080\n",
            "Epoch 600/5000, Loss: 0.0239, Validation Loss: 0.0076\n",
            "Epoch 700/5000, Loss: 0.0228, Validation Loss: 0.0074\n",
            "Epoch 800/5000, Loss: 0.0219, Validation Loss: 0.0072\n",
            "Epoch 900/5000, Loss: 0.0213, Validation Loss: 0.0070\n",
            "Epoch 1000/5000, Loss: 0.0207, Validation Loss: 0.0068\n",
            "Epoch 1100/5000, Loss: 0.0202, Validation Loss: 0.0066\n",
            "Epoch 1200/5000, Loss: 0.0197, Validation Loss: 0.0065\n",
            "Epoch 1300/5000, Loss: 0.0193, Validation Loss: 0.0063\n",
            "Epoch 1400/5000, Loss: 0.0189, Validation Loss: 0.0062\n",
            "Epoch 1500/5000, Loss: 0.0185, Validation Loss: 0.0061\n",
            "Epoch 1600/5000, Loss: 0.0182, Validation Loss: 0.0059\n",
            "Epoch 1700/5000, Loss: 0.0180, Validation Loss: 0.0058\n",
            "Epoch 1800/5000, Loss: 0.0177, Validation Loss: 0.0056\n",
            "Epoch 1900/5000, Loss: 0.0175, Validation Loss: 0.0055\n",
            "Epoch 2000/5000, Loss: 0.0173, Validation Loss: 0.0054\n",
            "Epoch 2100/5000, Loss: 0.0170, Validation Loss: 0.0055\n",
            "Epoch 2200/5000, Loss: 0.0168, Validation Loss: 0.0056\n",
            "Epoch 2300/5000, Loss: 0.0167, Validation Loss: 0.0055\n",
            "Epoch 2400/5000, Loss: 0.0166, Validation Loss: 0.0055\n",
            "Epoch 2500/5000, Loss: 0.0164, Validation Loss: 0.0054\n",
            "Epoch 2600/5000, Loss: 0.0163, Validation Loss: 0.0054\n",
            "Epoch 2700/5000, Loss: 0.0162, Validation Loss: 0.0053\n",
            "Epoch 2800/5000, Loss: 0.0161, Validation Loss: 0.0052\n",
            "Epoch 2900/5000, Loss: 0.0160, Validation Loss: 0.0051\n",
            "Epoch 3000/5000, Loss: 0.0160, Validation Loss: 0.0050\n",
            "Epoch 3100/5000, Loss: 0.0159, Validation Loss: 0.0049\n",
            "Epoch 3200/5000, Loss: 0.0158, Validation Loss: 0.0048\n",
            "Epoch 3300/5000, Loss: 0.0157, Validation Loss: 0.0048\n",
            "Epoch 3400/5000, Loss: 0.0157, Validation Loss: 0.0047\n",
            "Epoch 3500/5000, Loss: 0.0156, Validation Loss: 0.0046\n",
            "Epoch 3600/5000, Loss: 0.0155, Validation Loss: 0.0045\n",
            "Epoch 3700/5000, Loss: 0.0155, Validation Loss: 0.0044\n",
            "Epoch 3800/5000, Loss: 0.0154, Validation Loss: 0.0044\n",
            "Epoch 3900/5000, Loss: 0.0153, Validation Loss: 0.0043\n",
            "Epoch 4000/5000, Loss: 0.0153, Validation Loss: 0.0042\n",
            "Epoch 4100/5000, Loss: 0.0152, Validation Loss: 0.0041\n",
            "Epoch 4200/5000, Loss: 0.0152, Validation Loss: 0.0041\n",
            "Epoch 4300/5000, Loss: 0.0151, Validation Loss: 0.0040\n",
            "Epoch 4400/5000, Loss: 0.0151, Validation Loss: 0.0039\n",
            "Epoch 4500/5000, Loss: 0.0150, Validation Loss: 0.0039\n",
            "Epoch 4600/5000, Loss: 0.0150, Validation Loss: 0.0038\n",
            "Epoch 4700/5000, Loss: 0.0150, Validation Loss: 0.0038\n",
            "Epoch 4800/5000, Loss: 0.0149, Validation Loss: 0.0037\n",
            "Epoch 4900/5000, Loss: 0.0149, Validation Loss: 0.0037\n",
            "Completeness: 0.5548686244204019\n",
            "Purity: 0.2664334181509754\n",
            "SNPCC Figure of Merit: 0.059921996268520406\n",
            "10\n",
            "Epoch 0/5000, Loss: inf, Validation Loss: nan\n",
            "Epoch 100/5000, Loss: 0.2391, Validation Loss: 0.4714\n",
            "Epoch 200/5000, Loss: 0.1589, Validation Loss: 0.6130\n",
            "Epoch 300/5000, Loss: 0.0974, Validation Loss: 0.3502\n",
            "Epoch 400/5000, Loss: 0.0707, Validation Loss: 0.2237\n",
            "Epoch 500/5000, Loss: 0.0586, Validation Loss: 0.1675\n",
            "Epoch 600/5000, Loss: 0.0537, Validation Loss: 0.1491\n",
            "Epoch 700/5000, Loss: 0.0509, Validation Loss: 0.1422\n",
            "Epoch 800/5000, Loss: 0.0487, Validation Loss: 0.1378\n",
            "Epoch 900/5000, Loss: 0.0512, Validation Loss: 0.1344\n",
            "Epoch 1000/5000, Loss: 0.0476, Validation Loss: 0.1343\n",
            "Epoch 1100/5000, Loss: 0.0461, Validation Loss: 0.1322\n",
            "Epoch 1200/5000, Loss: 0.0447, Validation Loss: 0.1298\n",
            "Epoch 1300/5000, Loss: 0.0438, Validation Loss: 0.1292\n",
            "Epoch 1400/5000, Loss: 0.0430, Validation Loss: 0.1285\n",
            "Epoch 1500/5000, Loss: 0.0419, Validation Loss: 0.1280\n",
            "Epoch 1600/5000, Loss: 0.0414, Validation Loss: 0.1272\n",
            "Epoch 1700/5000, Loss: 0.0434, Validation Loss: 0.1211\n",
            "Epoch 1800/5000, Loss: 0.0418, Validation Loss: 0.1214\n",
            "Epoch 1900/5000, Loss: 0.0409, Validation Loss: 0.1220\n",
            "Epoch 2000/5000, Loss: 0.0403, Validation Loss: 0.1224\n",
            "Epoch 2100/5000, Loss: 0.0398, Validation Loss: 0.1227\n",
            "Epoch 2200/5000, Loss: 0.0394, Validation Loss: 0.1228\n",
            "Epoch 2300/5000, Loss: 0.0390, Validation Loss: 0.1229\n",
            "Epoch 2400/5000, Loss: 0.0387, Validation Loss: 0.1229\n",
            "Epoch 2500/5000, Loss: 0.0384, Validation Loss: 0.1229\n",
            "Epoch 2600/5000, Loss: 0.0382, Validation Loss: 0.1228\n",
            "Epoch 2700/5000, Loss: 0.0379, Validation Loss: 0.1227\n",
            "Epoch 2800/5000, Loss: 0.0377, Validation Loss: 0.1228\n",
            "Epoch 2900/5000, Loss: 0.0375, Validation Loss: 0.1227\n",
            "Epoch 3000/5000, Loss: 0.0373, Validation Loss: 0.1226\n",
            "Epoch 3100/5000, Loss: 0.0372, Validation Loss: 0.1225\n",
            "Epoch 3200/5000, Loss: 0.0370, Validation Loss: 0.1224\n",
            "Epoch 3300/5000, Loss: 0.0369, Validation Loss: 0.1224\n",
            "Epoch 3400/5000, Loss: 0.0367, Validation Loss: 0.1223\n",
            "Epoch 3500/5000, Loss: 0.0365, Validation Loss: 0.1222\n",
            "Epoch 3600/5000, Loss: 0.0364, Validation Loss: 0.1223\n",
            "Epoch 3700/5000, Loss: 0.0363, Validation Loss: 0.1222\n",
            "Epoch 3800/5000, Loss: 0.0366, Validation Loss: 0.1219\n",
            "Epoch 3900/5000, Loss: 0.0364, Validation Loss: 0.1217\n",
            "Epoch 4000/5000, Loss: 0.0363, Validation Loss: 0.1217\n",
            "Epoch 4100/5000, Loss: 0.0361, Validation Loss: 0.1217\n",
            "Epoch 4200/5000, Loss: 0.0360, Validation Loss: 0.1216\n",
            "Epoch 4300/5000, Loss: 0.0359, Validation Loss: 0.1216\n",
            "Epoch 4400/5000, Loss: 0.0358, Validation Loss: 0.1216\n",
            "Epoch 4500/5000, Loss: 0.0357, Validation Loss: 0.1215\n",
            "Epoch 4600/5000, Loss: 0.0356, Validation Loss: 0.1215\n",
            "Epoch 4700/5000, Loss: 0.0355, Validation Loss: 0.1214\n",
            "Epoch 4800/5000, Loss: 0.0354, Validation Loss: 0.1214\n",
            "Epoch 4900/5000, Loss: 0.0353, Validation Loss: 0.1213\n",
            "Completeness: 0.5946124972400089\n",
            "Purity: 0.25046502976190477\n",
            "SNPCC Figure of Merit: 0.059594025123459016\n",
            "20\n",
            "Epoch 0/5000, Loss: nan, Validation Loss: 5.3082\n",
            "Epoch 100/5000, Loss: 0.2699, Validation Loss: 0.2178\n",
            "Epoch 200/5000, Loss: 0.1585, Validation Loss: 0.1550\n",
            "Epoch 300/5000, Loss: 0.1203, Validation Loss: 0.1110\n",
            "Epoch 400/5000, Loss: 0.0934, Validation Loss: 0.0881\n",
            "Epoch 500/5000, Loss: 0.0819, Validation Loss: 0.0792\n",
            "Epoch 600/5000, Loss: 0.0754, Validation Loss: 0.0738\n",
            "Epoch 700/5000, Loss: 0.0685, Validation Loss: 0.0701\n",
            "Epoch 800/5000, Loss: 0.0653, Validation Loss: 0.0670\n",
            "Epoch 900/5000, Loss: 0.0628, Validation Loss: 0.0643\n",
            "Epoch 1000/5000, Loss: 0.0610, Validation Loss: 0.0613\n",
            "Epoch 1100/5000, Loss: 0.0593, Validation Loss: 0.0599\n",
            "Epoch 1200/5000, Loss: 0.0572, Validation Loss: 0.0610\n",
            "Epoch 1300/5000, Loss: 0.0537, Validation Loss: 0.0581\n",
            "Epoch 1400/5000, Loss: 0.0515, Validation Loss: 0.0566\n",
            "Epoch 1500/5000, Loss: 0.0502, Validation Loss: 0.0557\n",
            "Epoch 1600/5000, Loss: 0.0491, Validation Loss: 0.0547\n",
            "Epoch 1700/5000, Loss: 0.0482, Validation Loss: 0.0541\n",
            "Epoch 1800/5000, Loss: 0.0474, Validation Loss: 0.0536\n",
            "Epoch 1900/5000, Loss: 0.0470, Validation Loss: 0.0534\n",
            "Epoch 2000/5000, Loss: 0.0460, Validation Loss: 0.0525\n",
            "Epoch 2100/5000, Loss: 0.0454, Validation Loss: 0.0521\n",
            "Epoch 2200/5000, Loss: 0.0448, Validation Loss: 0.0518\n",
            "Epoch 2300/5000, Loss: 0.0441, Validation Loss: 0.0517\n",
            "Epoch 2400/5000, Loss: 0.0433, Validation Loss: 0.0517\n",
            "Epoch 2500/5000, Loss: 0.0427, Validation Loss: 0.0514\n",
            "Epoch 2600/5000, Loss: 0.0421, Validation Loss: 0.0511\n",
            "Epoch 2700/5000, Loss: 0.0415, Validation Loss: 0.0508\n",
            "Epoch 2800/5000, Loss: 0.0410, Validation Loss: 0.0506\n",
            "Epoch 2900/5000, Loss: 0.0409, Validation Loss: 0.0502\n",
            "Epoch 3000/5000, Loss: 0.0403, Validation Loss: 0.0501\n",
            "Epoch 3100/5000, Loss: 0.0399, Validation Loss: 0.0500\n",
            "Epoch 3200/5000, Loss: 0.0396, Validation Loss: 0.0498\n",
            "Epoch 3300/5000, Loss: 0.0393, Validation Loss: 0.0495\n",
            "Epoch 3400/5000, Loss: 0.0391, Validation Loss: 0.0494\n",
            "Epoch 3500/5000, Loss: 0.0388, Validation Loss: 0.0492\n",
            "Epoch 3600/5000, Loss: 0.0386, Validation Loss: 0.0490\n",
            "Epoch 3700/5000, Loss: 0.0384, Validation Loss: 0.0489\n",
            "Epoch 3800/5000, Loss: 0.0382, Validation Loss: 0.0487\n",
            "Epoch 3900/5000, Loss: 0.0380, Validation Loss: 0.0486\n",
            "Epoch 4000/5000, Loss: 0.0378, Validation Loss: 0.0485\n",
            "Epoch 4100/5000, Loss: 0.0376, Validation Loss: 0.0484\n",
            "Epoch 4200/5000, Loss: 0.0374, Validation Loss: 0.0482\n",
            "Epoch 4300/5000, Loss: 0.0372, Validation Loss: 0.0481\n",
            "Epoch 4400/5000, Loss: 0.0371, Validation Loss: 0.0480\n",
            "Epoch 4500/5000, Loss: 0.0369, Validation Loss: 0.0479\n",
            "Epoch 4600/5000, Loss: 0.0367, Validation Loss: 0.0479\n",
            "Epoch 4700/5000, Loss: 0.0366, Validation Loss: 0.0478\n",
            "Epoch 4800/5000, Loss: 0.0364, Validation Loss: 0.0477\n",
            "Epoch 4900/5000, Loss: 0.0363, Validation Loss: 0.0476\n",
            "Completeness: 0.5277103113270037\n",
            "Purity: 0.2632448507544884\n",
            "SNPCC Figure of Merit: 0.0561618935775722\n",
            "30\n",
            "Epoch 0/5000, Loss: nan, Validation Loss: 4.7001\n",
            "Epoch 100/5000, Loss: 0.2421, Validation Loss: 0.1455\n",
            "Epoch 200/5000, Loss: 0.1722, Validation Loss: 0.1106\n",
            "Epoch 300/5000, Loss: 0.1359, Validation Loss: 0.0808\n",
            "Epoch 400/5000, Loss: 0.1207, Validation Loss: 0.0687\n",
            "Epoch 500/5000, Loss: 0.1141, Validation Loss: 0.0644\n",
            "Epoch 600/5000, Loss: 0.1095, Validation Loss: 0.0619\n",
            "Epoch 700/5000, Loss: 0.1055, Validation Loss: 0.0608\n",
            "Epoch 800/5000, Loss: 0.1025, Validation Loss: 0.0597\n",
            "Epoch 900/5000, Loss: 0.1003, Validation Loss: 0.0586\n",
            "Epoch 1000/5000, Loss: 0.0984, Validation Loss: 0.0577\n",
            "Epoch 1100/5000, Loss: 0.0967, Validation Loss: 0.0569\n",
            "Epoch 1200/5000, Loss: 0.0997, Validation Loss: 0.0555\n",
            "Epoch 1300/5000, Loss: 0.0963, Validation Loss: 0.0546\n",
            "Epoch 1400/5000, Loss: 0.0945, Validation Loss: 0.0540\n",
            "Epoch 1500/5000, Loss: 0.0928, Validation Loss: 0.0538\n",
            "Epoch 1600/5000, Loss: 0.0915, Validation Loss: 0.0536\n",
            "Epoch 1700/5000, Loss: 0.0905, Validation Loss: 0.0533\n",
            "Epoch 1800/5000, Loss: 0.0896, Validation Loss: 0.0530\n",
            "Epoch 1900/5000, Loss: 0.0886, Validation Loss: 0.0528\n",
            "Epoch 2000/5000, Loss: 0.0879, Validation Loss: 0.0525\n",
            "Epoch 2100/5000, Loss: 0.0873, Validation Loss: 0.0523\n",
            "Epoch 2200/5000, Loss: 0.0867, Validation Loss: 0.0521\n",
            "Epoch 2300/5000, Loss: 0.0861, Validation Loss: 0.0519\n",
            "Epoch 2400/5000, Loss: 0.0856, Validation Loss: 0.0518\n",
            "Epoch 2500/5000, Loss: 0.0852, Validation Loss: 0.0516\n",
            "Epoch 2600/5000, Loss: 0.0847, Validation Loss: 0.0514\n",
            "Epoch 2700/5000, Loss: 0.0843, Validation Loss: 0.0512\n",
            "Epoch 2800/5000, Loss: 0.0838, Validation Loss: 0.0510\n",
            "Epoch 2900/5000, Loss: 0.0834, Validation Loss: 0.0507\n",
            "Epoch 3000/5000, Loss: 0.0830, Validation Loss: 0.0505\n",
            "Epoch 3100/5000, Loss: 0.0826, Validation Loss: 0.0503\n",
            "Epoch 3200/5000, Loss: 0.0823, Validation Loss: 0.0501\n",
            "Epoch 3300/5000, Loss: 0.0820, Validation Loss: 0.0499\n",
            "Epoch 3400/5000, Loss: 0.0817, Validation Loss: 0.0497\n",
            "Epoch 3500/5000, Loss: 0.0813, Validation Loss: 0.0496\n",
            "Epoch 3600/5000, Loss: 0.0810, Validation Loss: 0.0494\n",
            "Epoch 3700/5000, Loss: 0.0808, Validation Loss: 0.0492\n",
            "Epoch 3800/5000, Loss: 0.0805, Validation Loss: 0.0491\n",
            "Epoch 3900/5000, Loss: 0.0803, Validation Loss: 0.0490\n",
            "Epoch 4000/5000, Loss: 0.0801, Validation Loss: 0.0488\n",
            "Epoch 4100/5000, Loss: 0.0798, Validation Loss: 0.0486\n",
            "Epoch 4200/5000, Loss: 0.0796, Validation Loss: 0.0484\n",
            "Epoch 4300/5000, Loss: 0.0794, Validation Loss: 0.0483\n",
            "Epoch 4400/5000, Loss: 0.0793, Validation Loss: 0.0482\n",
            "Epoch 4500/5000, Loss: 0.0811, Validation Loss: 0.0481\n",
            "Epoch 4600/5000, Loss: 0.0802, Validation Loss: 0.0480\n",
            "Epoch 4700/5000, Loss: 0.0799, Validation Loss: 0.0479\n",
            "Epoch 4800/5000, Loss: 0.0797, Validation Loss: 0.0478\n",
            "Epoch 4900/5000, Loss: 0.0794, Validation Loss: 0.0477\n",
            "Completeness: 0.6491499227202473\n",
            "Purity: 0.27161862527716185\n",
            "SNPCC Figure of Merit: 0.07176973423576741\n",
            "40\n",
            "Epoch 0/5000, Loss: nan, Validation Loss: 4.0145\n",
            "Epoch 100/5000, Loss: 0.7388, Validation Loss: 1.0422\n",
            "Epoch 200/5000, Loss: 0.6249, Validation Loss: 0.9944\n",
            "Epoch 300/5000, Loss: 0.2658, Validation Loss: 0.3440\n",
            "Epoch 400/5000, Loss: 0.1823, Validation Loss: 0.1800\n",
            "Epoch 500/5000, Loss: 0.1652, Validation Loss: 0.1312\n",
            "Epoch 600/5000, Loss: 0.1508, Validation Loss: 0.1112\n",
            "Epoch 700/5000, Loss: 0.1453, Validation Loss: 0.1186\n",
            "Epoch 800/5000, Loss: 0.1366, Validation Loss: 0.1067\n",
            "Epoch 900/5000, Loss: 0.1325, Validation Loss: 0.0964\n",
            "Epoch 1000/5000, Loss: 0.1266, Validation Loss: 0.0908\n",
            "Epoch 1100/5000, Loss: 0.1238, Validation Loss: 0.0869\n",
            "Epoch 1200/5000, Loss: 0.1186, Validation Loss: 0.0838\n",
            "Epoch 1300/5000, Loss: 0.1156, Validation Loss: 0.0779\n",
            "Epoch 1400/5000, Loss: 0.1121, Validation Loss: 0.0757\n",
            "Epoch 1500/5000, Loss: 0.1087, Validation Loss: 0.0737\n",
            "Epoch 1600/5000, Loss: 0.1081, Validation Loss: 0.0690\n",
            "Epoch 1700/5000, Loss: 0.1037, Validation Loss: 0.0686\n",
            "Epoch 1800/5000, Loss: 0.1012, Validation Loss: 0.0676\n",
            "Epoch 1900/5000, Loss: 0.0989, Validation Loss: 0.0666\n",
            "Epoch 2000/5000, Loss: 0.1002, Validation Loss: 0.0664\n",
            "Epoch 2100/5000, Loss: 0.1003, Validation Loss: 0.0654\n",
            "Epoch 2200/5000, Loss: 0.0955, Validation Loss: 0.0639\n",
            "Epoch 2300/5000, Loss: 0.0963, Validation Loss: 0.0631\n",
            "Epoch 2400/5000, Loss: 0.0943, Validation Loss: 0.0622\n",
            "Epoch 2500/5000, Loss: 0.0926, Validation Loss: 0.0614\n",
            "Epoch 2600/5000, Loss: 0.0911, Validation Loss: 0.0607\n",
            "Epoch 2700/5000, Loss: 0.0899, Validation Loss: 0.0601\n",
            "Epoch 2800/5000, Loss: 0.0888, Validation Loss: 0.0595\n",
            "Epoch 2900/5000, Loss: 0.0878, Validation Loss: 0.0590\n",
            "Epoch 3000/5000, Loss: 0.0869, Validation Loss: 0.0585\n",
            "Epoch 3100/5000, Loss: 0.0860, Validation Loss: 0.0580\n",
            "Epoch 3200/5000, Loss: 0.0852, Validation Loss: 0.0575\n",
            "Epoch 3300/5000, Loss: 0.0844, Validation Loss: 0.0571\n",
            "Epoch 3400/5000, Loss: 0.0837, Validation Loss: 0.0567\n",
            "Epoch 3500/5000, Loss: 0.0842, Validation Loss: 0.0561\n",
            "Epoch 3600/5000, Loss: 0.0833, Validation Loss: 0.0559\n",
            "Epoch 3700/5000, Loss: 0.0821, Validation Loss: 0.0554\n",
            "Epoch 3800/5000, Loss: 0.0822, Validation Loss: 0.0549\n",
            "Epoch 3900/5000, Loss: 0.0814, Validation Loss: 0.0547\n",
            "Epoch 4000/5000, Loss: 0.0808, Validation Loss: 0.0544\n",
            "Epoch 4100/5000, Loss: 0.0802, Validation Loss: 0.0541\n",
            "Epoch 4200/5000, Loss: 0.0797, Validation Loss: 0.0538\n",
            "Epoch 4300/5000, Loss: 0.0792, Validation Loss: 0.0536\n",
            "Epoch 4400/5000, Loss: 0.0788, Validation Loss: 0.0533\n",
            "Epoch 4500/5000, Loss: 0.0784, Validation Loss: 0.0531\n",
            "Epoch 4600/5000, Loss: 0.0780, Validation Loss: 0.0528\n",
            "Epoch 4700/5000, Loss: 0.0776, Validation Loss: 0.0526\n",
            "Epoch 4800/5000, Loss: 0.0773, Validation Loss: 0.0524\n",
            "Epoch 4900/5000, Loss: 0.0769, Validation Loss: 0.0522\n",
            "Completeness: 0.6228748068006182\n",
            "Purity: 0.26438612933458294\n",
            "SNPCC Figure of Merit: 0.06663872231434102\n",
            "50\n",
            "Epoch 0/5000, Loss: nan, Validation Loss: 7.8412\n",
            "Epoch 100/5000, Loss: 0.8274, Validation Loss: 1.1109\n",
            "Epoch 200/5000, Loss: 0.4935, Validation Loss: 0.7552\n",
            "Epoch 300/5000, Loss: 0.4561, Validation Loss: 0.7142\n",
            "Epoch 400/5000, Loss: 0.3629, Validation Loss: 0.6189\n",
            "Epoch 500/5000, Loss: 0.2959, Validation Loss: 0.5400\n",
            "Epoch 600/5000, Loss: 0.2731, Validation Loss: 0.4855\n",
            "Epoch 700/5000, Loss: 0.2501, Validation Loss: 0.4067\n",
            "Epoch 800/5000, Loss: 0.2346, Validation Loss: 0.3499\n",
            "Epoch 900/5000, Loss: 0.2146, Validation Loss: 0.3321\n",
            "Epoch 1000/5000, Loss: 0.2026, Validation Loss: 0.3016\n",
            "Epoch 1100/5000, Loss: 0.1915, Validation Loss: 0.2726\n",
            "Epoch 1200/5000, Loss: 0.1831, Validation Loss: 0.2724\n",
            "Epoch 1300/5000, Loss: 0.1784, Validation Loss: 0.2406\n",
            "Epoch 1400/5000, Loss: 0.1691, Validation Loss: 0.2193\n",
            "Epoch 1500/5000, Loss: 0.1606, Validation Loss: 0.1896\n",
            "Epoch 1600/5000, Loss: 0.1538, Validation Loss: 0.1816\n",
            "Epoch 1700/5000, Loss: 0.1507, Validation Loss: 0.1670\n",
            "Epoch 1800/5000, Loss: 0.1467, Validation Loss: 0.1631\n",
            "Epoch 1900/5000, Loss: 0.1437, Validation Loss: 0.1595\n",
            "Epoch 2000/5000, Loss: 0.1409, Validation Loss: 0.1574\n",
            "Epoch 2100/5000, Loss: 0.1372, Validation Loss: 0.1492\n",
            "Epoch 2200/5000, Loss: 0.1314, Validation Loss: 0.1469\n",
            "Epoch 2300/5000, Loss: 0.1287, Validation Loss: 0.1455\n",
            "Epoch 2400/5000, Loss: 0.1273, Validation Loss: 0.1428\n",
            "Epoch 2500/5000, Loss: 0.1250, Validation Loss: 0.1410\n",
            "Epoch 2600/5000, Loss: 0.1228, Validation Loss: 0.1384\n",
            "Epoch 2700/5000, Loss: 0.1213, Validation Loss: 0.1374\n",
            "Epoch 2800/5000, Loss: 0.1184, Validation Loss: 0.1343\n",
            "Epoch 2900/5000, Loss: 0.1150, Validation Loss: 0.1296\n",
            "Epoch 3000/5000, Loss: 0.1127, Validation Loss: 0.1266\n",
            "Epoch 3100/5000, Loss: 0.1107, Validation Loss: 0.1239\n",
            "Epoch 3200/5000, Loss: 0.1089, Validation Loss: 0.1215\n",
            "Epoch 3300/5000, Loss: 0.1072, Validation Loss: 0.1194\n",
            "Epoch 3400/5000, Loss: 0.1059, Validation Loss: 0.1176\n",
            "Epoch 3500/5000, Loss: 0.1048, Validation Loss: 0.1159\n",
            "Epoch 3600/5000, Loss: 0.1037, Validation Loss: 0.1142\n",
            "Epoch 3700/5000, Loss: 0.1027, Validation Loss: 0.1119\n",
            "Epoch 3800/5000, Loss: 0.1022, Validation Loss: 0.1116\n",
            "Epoch 3900/5000, Loss: 0.1012, Validation Loss: 0.1106\n",
            "Epoch 4000/5000, Loss: 0.1004, Validation Loss: 0.1107\n",
            "Epoch 4100/5000, Loss: 0.0994, Validation Loss: 0.1094\n",
            "Epoch 4200/5000, Loss: 0.0983, Validation Loss: 0.1080\n",
            "Epoch 4300/5000, Loss: 0.0972, Validation Loss: 0.1066\n",
            "Epoch 4400/5000, Loss: 0.0960, Validation Loss: 0.1030\n",
            "Epoch 4500/5000, Loss: 0.0953, Validation Loss: 0.1024\n",
            "Epoch 4600/5000, Loss: 0.0943, Validation Loss: 0.1012\n",
            "Epoch 4700/5000, Loss: 0.0941, Validation Loss: 0.1015\n",
            "Epoch 4800/5000, Loss: 0.0937, Validation Loss: 0.1013\n",
            "Epoch 4900/5000, Loss: 0.0921, Validation Loss: 0.0980\n",
            "Completeness: 0.647162729079267\n",
            "Purity: 0.274721154747399\n",
            "SNPCC Figure of Merit: 0.07255054346648811\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of elements to select\n",
        "percentages = [5,10,20,30,40,50,100]\n",
        "for percentage in percentages:\n",
        "  num_elements_to_select = int(len(X_train) * (percentage / 100.0))\n",
        "\n",
        "  # Use numpy.random.choice to get random indices\n",
        "  random_indices = np.random.choice(len(X_train), size=num_elements_to_select, replace=False)\n",
        "\n",
        "  # Get the selected elements from the original array\n",
        "  X_train_local = X_train[random_indices]\n",
        "  y_train_local = y_train[random_indices]\n",
        "  X_test_local = X_test\n",
        "  GLOBAL_SAMPLE_SIZE.append(percentage)\n",
        "  GLOBAL_Z_USED.append('yes')\n",
        "  neural_network(True,5000,0.1,X_train_local,y_train_local,X_test_local)\n",
        "  print(percentage)"
      ],
      "metadata": {
        "id": "pDp7iMX2Era1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3257bc05-f82c-4503-c808-56c50cd24122"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/5000, Loss: nan, Validation Loss: 5.3996\n",
            "Epoch 100/5000, Loss: 0.0355, Validation Loss: 0.0023\n",
            "Epoch 200/5000, Loss: 0.0199, Validation Loss: 0.0011\n",
            "Epoch 300/5000, Loss: 0.0143, Validation Loss: 0.0006\n",
            "Epoch 400/5000, Loss: 0.0112, Validation Loss: 0.0005\n",
            "Epoch 500/5000, Loss: 0.0092, Validation Loss: 0.0004\n",
            "Epoch 600/5000, Loss: 0.0078, Validation Loss: 0.0003\n",
            "Epoch 700/5000, Loss: 0.0067, Validation Loss: 0.0002\n",
            "Epoch 800/5000, Loss: 0.0059, Validation Loss: 0.0002\n",
            "Epoch 900/5000, Loss: 0.0053, Validation Loss: 0.0001\n",
            "Epoch 1000/5000, Loss: 0.0047, Validation Loss: 0.0001\n",
            "Epoch 1100/5000, Loss: 0.0043, Validation Loss: 0.0001\n",
            "Epoch 1200/5000, Loss: 0.0040, Validation Loss: 0.0001\n",
            "Epoch 1300/5000, Loss: 0.0037, Validation Loss: 0.0001\n",
            "Epoch 1400/5000, Loss: 0.0034, Validation Loss: 0.0001\n",
            "Epoch 1500/5000, Loss: 0.0032, Validation Loss: 0.0001\n",
            "Epoch 1600/5000, Loss: 0.0030, Validation Loss: 0.0001\n",
            "Epoch 1700/5000, Loss: 0.0029, Validation Loss: 0.0001\n",
            "Epoch 1800/5000, Loss: 0.0027, Validation Loss: 0.0001\n",
            "Epoch 1900/5000, Loss: 0.0026, Validation Loss: 0.0001\n",
            "Epoch 2000/5000, Loss: 0.0023, Validation Loss: 0.0001\n",
            "Epoch 2100/5000, Loss: 0.0022, Validation Loss: 0.0001\n",
            "Epoch 2200/5000, Loss: 0.0021, Validation Loss: 0.0001\n",
            "Epoch 2300/5000, Loss: 0.0020, Validation Loss: 0.0001\n",
            "Epoch 2400/5000, Loss: 0.0019, Validation Loss: 0.0001\n",
            "Epoch 2500/5000, Loss: 0.0019, Validation Loss: 0.0001\n",
            "Epoch 2600/5000, Loss: 0.0018, Validation Loss: 0.0001\n",
            "Epoch 2700/5000, Loss: 0.0017, Validation Loss: 0.0000\n",
            "Epoch 2800/5000, Loss: 0.0017, Validation Loss: 0.0000\n",
            "Epoch 2900/5000, Loss: 0.0016, Validation Loss: 0.0000\n",
            "Epoch 3000/5000, Loss: 0.0016, Validation Loss: 0.0000\n",
            "Epoch 3100/5000, Loss: 0.0015, Validation Loss: 0.0000\n",
            "Epoch 3200/5000, Loss: 0.0015, Validation Loss: 0.0000\n",
            "Epoch 3300/5000, Loss: 0.0014, Validation Loss: 0.0000\n",
            "Epoch 3400/5000, Loss: 0.0014, Validation Loss: 0.0000\n",
            "Epoch 3500/5000, Loss: 0.0015, Validation Loss: 0.0000\n",
            "Epoch 3600/5000, Loss: 0.0014, Validation Loss: 0.0000\n",
            "Epoch 3700/5000, Loss: 0.0014, Validation Loss: 0.0000\n",
            "Epoch 3800/5000, Loss: 0.0013, Validation Loss: 0.0000\n",
            "Epoch 3900/5000, Loss: 0.0013, Validation Loss: 0.0000\n",
            "Epoch 4000/5000, Loss: 0.0012, Validation Loss: 0.0000\n",
            "Epoch 4100/5000, Loss: 0.0012, Validation Loss: 0.0000\n",
            "Epoch 4200/5000, Loss: 0.0012, Validation Loss: 0.0000\n",
            "Epoch 4300/5000, Loss: 0.0012, Validation Loss: 0.0000\n",
            "Epoch 4400/5000, Loss: 0.0011, Validation Loss: 0.0000\n",
            "Epoch 4500/5000, Loss: 0.0011, Validation Loss: 0.0000\n",
            "Epoch 4600/5000, Loss: 0.0011, Validation Loss: 0.0000\n",
            "Epoch 4700/5000, Loss: 0.0011, Validation Loss: 0.0000\n",
            "Epoch 4800/5000, Loss: 0.0010, Validation Loss: 0.0000\n",
            "Epoch 4900/5000, Loss: 0.0010, Validation Loss: 0.0000\n",
            "Completeness: 0.5968204901744314\n",
            "Purity: 0.29045776918117344\n",
            "SNPCC Figure of Merit: 0.07165981631758565\n",
            "5\n",
            "Epoch 0/5000, Loss: 12.7937, Validation Loss: 10.3937\n",
            "Epoch 100/5000, Loss: 0.3082, Validation Loss: 1.1023\n",
            "Epoch 200/5000, Loss: 0.1126, Validation Loss: 0.0989\n",
            "Epoch 300/5000, Loss: 0.0988, Validation Loss: 0.0488\n",
            "Epoch 400/5000, Loss: 0.0914, Validation Loss: 0.0458\n",
            "Epoch 500/5000, Loss: 0.0855, Validation Loss: 0.0427\n",
            "Epoch 600/5000, Loss: 0.0806, Validation Loss: 0.0414\n",
            "Epoch 700/5000, Loss: 0.0758, Validation Loss: 0.0412\n",
            "Epoch 800/5000, Loss: 0.0718, Validation Loss: 0.0408\n",
            "Epoch 900/5000, Loss: 0.0680, Validation Loss: 0.0407\n",
            "Epoch 1000/5000, Loss: 0.0645, Validation Loss: 0.0395\n",
            "Epoch 1100/5000, Loss: 0.0615, Validation Loss: 0.0393\n",
            "Epoch 1200/5000, Loss: 0.0589, Validation Loss: 0.0391\n",
            "Epoch 1300/5000, Loss: 0.0565, Validation Loss: 0.0390\n",
            "Epoch 1400/5000, Loss: 0.0546, Validation Loss: 0.0389\n",
            "Epoch 1500/5000, Loss: 0.0529, Validation Loss: 0.0389\n",
            "Epoch 1600/5000, Loss: 0.0514, Validation Loss: 0.0388\n",
            "Epoch 1700/5000, Loss: 0.0501, Validation Loss: 0.0387\n",
            "Epoch 1800/5000, Loss: 0.0492, Validation Loss: 0.0396\n",
            "Epoch 1900/5000, Loss: 0.0481, Validation Loss: 0.0392\n",
            "Epoch 2000/5000, Loss: 0.0472, Validation Loss: 0.0390\n",
            "Epoch 2100/5000, Loss: 0.0464, Validation Loss: 0.0389\n",
            "Epoch 2200/5000, Loss: 0.0457, Validation Loss: 0.0388\n",
            "Epoch 2300/5000, Loss: 0.0450, Validation Loss: 0.0388\n",
            "Epoch 2400/5000, Loss: 0.0444, Validation Loss: 0.0387\n",
            "Epoch 2500/5000, Loss: 0.0439, Validation Loss: 0.0386\n",
            "Epoch 2600/5000, Loss: 0.0434, Validation Loss: 0.0386\n",
            "Epoch 2700/5000, Loss: 0.0430, Validation Loss: 0.0385\n",
            "Epoch 2800/5000, Loss: 0.0426, Validation Loss: 0.0385\n",
            "Epoch 2900/5000, Loss: 0.0422, Validation Loss: 0.0384\n",
            "Epoch 3000/5000, Loss: 0.0419, Validation Loss: 0.0384\n",
            "Epoch 3100/5000, Loss: 0.0416, Validation Loss: 0.0383\n",
            "Epoch 3200/5000, Loss: 0.0413, Validation Loss: 0.0383\n",
            "Epoch 3300/5000, Loss: 0.0419, Validation Loss: 0.0374\n",
            "Epoch 3400/5000, Loss: 0.0414, Validation Loss: 0.0380\n",
            "Epoch 3500/5000, Loss: 0.0410, Validation Loss: 0.0379\n",
            "Epoch 3600/5000, Loss: 0.0407, Validation Loss: 0.0378\n",
            "Epoch 3700/5000, Loss: 0.0405, Validation Loss: 0.0378\n",
            "Epoch 3800/5000, Loss: 0.0402, Validation Loss: 0.0378\n",
            "Epoch 3900/5000, Loss: 0.0400, Validation Loss: 0.0378\n",
            "Epoch 4000/5000, Loss: 0.0398, Validation Loss: 0.0377\n",
            "Epoch 4100/5000, Loss: 0.0396, Validation Loss: 0.0377\n",
            "Epoch 4200/5000, Loss: 0.0394, Validation Loss: 0.0377\n",
            "Epoch 4300/5000, Loss: 0.0393, Validation Loss: 0.0377\n",
            "Epoch 4400/5000, Loss: 0.0392, Validation Loss: 0.0377\n",
            "Epoch 4500/5000, Loss: 0.0390, Validation Loss: 0.0377\n",
            "Epoch 4600/5000, Loss: 0.0389, Validation Loss: 0.0377\n",
            "Epoch 4700/5000, Loss: 0.0388, Validation Loss: 0.0377\n",
            "Epoch 4800/5000, Loss: 0.0387, Validation Loss: 0.0377\n",
            "Epoch 4900/5000, Loss: 0.0386, Validation Loss: 0.0376\n",
            "Completeness: 0.6067564583793332\n",
            "Purity: 0.28086672117743255\n",
            "SNPCC Figure of Merit: 0.06989297231834371\n",
            "10\n",
            "Epoch 0/5000, Loss: 8.7651, Validation Loss: nan\n",
            "Epoch 100/5000, Loss: 0.4412, Validation Loss: 0.0925\n",
            "Epoch 200/5000, Loss: 0.2356, Validation Loss: 0.0951\n",
            "Epoch 300/5000, Loss: 0.1664, Validation Loss: 0.0944\n",
            "Epoch 400/5000, Loss: 0.1363, Validation Loss: 0.0927\n",
            "Epoch 500/5000, Loss: 0.1172, Validation Loss: 0.0919\n",
            "Epoch 600/5000, Loss: 0.1071, Validation Loss: 0.0909\n",
            "Epoch 700/5000, Loss: 0.1010, Validation Loss: 0.0904\n",
            "Epoch 800/5000, Loss: 0.0968, Validation Loss: 0.0905\n",
            "Epoch 900/5000, Loss: 0.0967, Validation Loss: 0.0894\n",
            "Epoch 1000/5000, Loss: 0.0934, Validation Loss: 0.0899\n",
            "Epoch 1100/5000, Loss: 0.0910, Validation Loss: 0.0904\n",
            "Epoch 1200/5000, Loss: 0.0890, Validation Loss: 0.0909\n",
            "Epoch 1300/5000, Loss: 0.0875, Validation Loss: 0.0913\n",
            "Epoch 1400/5000, Loss: 0.0861, Validation Loss: 0.0915\n",
            "Epoch 1500/5000, Loss: 0.0848, Validation Loss: 0.0915\n",
            "Epoch 1600/5000, Loss: 0.0837, Validation Loss: 0.0918\n",
            "Epoch 1700/5000, Loss: 0.0828, Validation Loss: 0.0920\n",
            "Epoch 1800/5000, Loss: 0.0821, Validation Loss: 0.0922\n",
            "Epoch 1900/5000, Loss: 0.0814, Validation Loss: 0.0924\n",
            "Epoch 2000/5000, Loss: 0.0807, Validation Loss: 0.0925\n",
            "Epoch 2100/5000, Loss: 0.0801, Validation Loss: 0.0926\n",
            "Epoch 2200/5000, Loss: 0.0795, Validation Loss: 0.0927\n",
            "Epoch 2300/5000, Loss: 0.0790, Validation Loss: 0.0928\n",
            "Epoch 2400/5000, Loss: 0.0786, Validation Loss: 0.0929\n",
            "Epoch 2500/5000, Loss: 0.0782, Validation Loss: 0.0929\n",
            "Epoch 2600/5000, Loss: 0.0778, Validation Loss: 0.0931\n",
            "Epoch 2700/5000, Loss: 0.0775, Validation Loss: 0.0932\n",
            "Epoch 2800/5000, Loss: 0.0772, Validation Loss: 0.0933\n",
            "Epoch 2900/5000, Loss: 0.0770, Validation Loss: 0.0933\n",
            "Epoch 3000/5000, Loss: 0.0768, Validation Loss: 0.0934\n",
            "Epoch 3100/5000, Loss: 0.0766, Validation Loss: 0.0935\n",
            "Epoch 3200/5000, Loss: 0.0763, Validation Loss: 0.0936\n",
            "Epoch 3300/5000, Loss: 0.0761, Validation Loss: 0.0936\n",
            "Epoch 3400/5000, Loss: 0.0760, Validation Loss: 0.0936\n",
            "Epoch 3500/5000, Loss: 0.0758, Validation Loss: 0.0939\n",
            "Epoch 3600/5000, Loss: 0.0758, Validation Loss: 0.0939\n",
            "Epoch 3700/5000, Loss: 0.0757, Validation Loss: 0.0939\n",
            "Epoch 3800/5000, Loss: 0.0755, Validation Loss: 0.0939\n",
            "Epoch 3900/5000, Loss: 0.0754, Validation Loss: 0.0939\n",
            "Epoch 4000/5000, Loss: 0.0752, Validation Loss: 0.0940\n",
            "Epoch 4100/5000, Loss: 0.0751, Validation Loss: 0.0940\n",
            "Epoch 4200/5000, Loss: 0.0805, Validation Loss: 0.0905\n",
            "Epoch 4300/5000, Loss: 0.0755, Validation Loss: 0.0945\n",
            "Epoch 4400/5000, Loss: 0.0752, Validation Loss: 0.0944\n",
            "Epoch 4500/5000, Loss: 0.0750, Validation Loss: 0.0944\n",
            "Epoch 4600/5000, Loss: 0.0749, Validation Loss: 0.0943\n",
            "Epoch 4700/5000, Loss: 0.0748, Validation Loss: 0.0943\n",
            "Epoch 4800/5000, Loss: 0.0747, Validation Loss: 0.0943\n",
            "Epoch 4900/5000, Loss: 0.0746, Validation Loss: 0.0943\n",
            "Completeness: 0.567674983440053\n",
            "Purity: 0.25948728300363344\n",
            "SNPCC Figure of Merit: 0.05937240185600749\n",
            "20\n",
            "Epoch 0/5000, Loss: 5.3219, Validation Loss: 4.5843\n",
            "Epoch 100/5000, Loss: 0.4980, Validation Loss: 0.3104\n",
            "Epoch 200/5000, Loss: 0.2497, Validation Loss: 0.1525\n",
            "Epoch 300/5000, Loss: 0.1863, Validation Loss: 0.1230\n",
            "Epoch 400/5000, Loss: 0.1468, Validation Loss: 0.1383\n",
            "Epoch 500/5000, Loss: 0.1192, Validation Loss: 0.1387\n",
            "Epoch 600/5000, Loss: 0.0994, Validation Loss: 0.1171\n",
            "Epoch 700/5000, Loss: 0.0919, Validation Loss: 0.1095\n",
            "Epoch 800/5000, Loss: 0.0933, Validation Loss: 0.1051\n",
            "Epoch 900/5000, Loss: 0.0852, Validation Loss: 0.1023\n",
            "Epoch 1000/5000, Loss: 0.0824, Validation Loss: 0.0999\n",
            "Epoch 1100/5000, Loss: 0.0797, Validation Loss: 0.0980\n",
            "Epoch 1200/5000, Loss: 0.0777, Validation Loss: 0.0966\n",
            "Epoch 1300/5000, Loss: 0.0762, Validation Loss: 0.0955\n",
            "Epoch 1400/5000, Loss: 0.0749, Validation Loss: 0.0944\n",
            "Epoch 1500/5000, Loss: 0.0738, Validation Loss: 0.0932\n",
            "Epoch 1600/5000, Loss: 0.0785, Validation Loss: 0.0929\n",
            "Epoch 1700/5000, Loss: 0.0760, Validation Loss: 0.0929\n",
            "Epoch 1800/5000, Loss: 0.0744, Validation Loss: 0.0919\n",
            "Epoch 1900/5000, Loss: 0.0722, Validation Loss: 0.0801\n",
            "Epoch 2000/5000, Loss: 0.0711, Validation Loss: 0.0789\n",
            "Epoch 2100/5000, Loss: 0.0703, Validation Loss: 0.0779\n",
            "Epoch 2200/5000, Loss: 0.0695, Validation Loss: 0.0771\n",
            "Epoch 2300/5000, Loss: 0.0689, Validation Loss: 0.0765\n",
            "Epoch 2400/5000, Loss: 0.0684, Validation Loss: 0.0759\n",
            "Epoch 2500/5000, Loss: 0.0678, Validation Loss: 0.0755\n",
            "Epoch 2600/5000, Loss: 0.0663, Validation Loss: 0.0751\n",
            "Epoch 2700/5000, Loss: 0.0660, Validation Loss: 0.0747\n",
            "Epoch 2800/5000, Loss: 0.0657, Validation Loss: 0.0743\n",
            "Epoch 2900/5000, Loss: 0.0655, Validation Loss: 0.0740\n",
            "Epoch 3000/5000, Loss: 0.0654, Validation Loss: 0.0738\n",
            "Epoch 3100/5000, Loss: 0.0660, Validation Loss: 0.0751\n",
            "Epoch 3200/5000, Loss: 0.0655, Validation Loss: 0.0720\n",
            "Epoch 3300/5000, Loss: 0.0656, Validation Loss: 0.0755\n",
            "Epoch 3400/5000, Loss: 0.0652, Validation Loss: 0.0747\n",
            "Epoch 3500/5000, Loss: 0.0650, Validation Loss: 0.0744\n",
            "Epoch 3600/5000, Loss: 0.0649, Validation Loss: 0.0742\n",
            "Epoch 3700/5000, Loss: 0.0647, Validation Loss: 0.0740\n",
            "Epoch 3800/5000, Loss: 0.0639, Validation Loss: 0.0761\n",
            "Epoch 3900/5000, Loss: 0.0636, Validation Loss: 0.0757\n",
            "Epoch 4000/5000, Loss: 0.0633, Validation Loss: 0.0752\n",
            "Epoch 4100/5000, Loss: 0.0644, Validation Loss: 0.0789\n",
            "Epoch 4200/5000, Loss: 0.0639, Validation Loss: 0.0783\n",
            "Epoch 4300/5000, Loss: 0.0635, Validation Loss: 0.0767\n",
            "Epoch 4400/5000, Loss: 0.0632, Validation Loss: 0.0758\n",
            "Epoch 4500/5000, Loss: 0.0629, Validation Loss: 0.0753\n",
            "Epoch 4600/5000, Loss: 0.0686, Validation Loss: 0.0808\n",
            "Epoch 4700/5000, Loss: 0.0644, Validation Loss: 0.0774\n",
            "Epoch 4800/5000, Loss: 0.0641, Validation Loss: 0.0762\n",
            "Epoch 4900/5000, Loss: 0.0658, Validation Loss: 0.0798\n",
            "Completeness: 0.5588430117023625\n",
            "Purity: 0.2752582925502991\n",
            "SNPCC Figure of Merit: 0.06279943447225857\n",
            "30\n",
            "Epoch 0/5000, Loss: nan, Validation Loss: nan\n",
            "Epoch 100/5000, Loss: nan, Validation Loss: 0.9815\n",
            "Epoch 200/5000, Loss: nan, Validation Loss: 0.6207\n",
            "Epoch 300/5000, Loss: 0.4006, Validation Loss: 0.5309\n",
            "Epoch 400/5000, Loss: 0.3139, Validation Loss: 0.4022\n",
            "Epoch 500/5000, Loss: 0.2647, Validation Loss: 0.2540\n",
            "Epoch 600/5000, Loss: 0.2290, Validation Loss: 0.2197\n",
            "Epoch 700/5000, Loss: 0.2038, Validation Loss: 0.1922\n",
            "Epoch 800/5000, Loss: 0.1842, Validation Loss: 0.1919\n",
            "Epoch 900/5000, Loss: 0.1698, Validation Loss: 0.2207\n",
            "Epoch 1000/5000, Loss: 0.1573, Validation Loss: 0.1940\n",
            "Epoch 1100/5000, Loss: 0.1482, Validation Loss: 0.1750\n",
            "Epoch 1200/5000, Loss: 0.1397, Validation Loss: 0.1644\n",
            "Epoch 1300/5000, Loss: 0.1336, Validation Loss: 0.1494\n",
            "Epoch 1400/5000, Loss: 0.1291, Validation Loss: 0.1484\n",
            "Epoch 1500/5000, Loss: 0.1239, Validation Loss: 0.1440\n",
            "Epoch 1600/5000, Loss: 0.1203, Validation Loss: 0.1410\n",
            "Epoch 1700/5000, Loss: 0.1168, Validation Loss: 0.1393\n",
            "Epoch 1800/5000, Loss: 0.1133, Validation Loss: 0.1359\n",
            "Epoch 1900/5000, Loss: 0.1109, Validation Loss: 0.1359\n",
            "Epoch 2000/5000, Loss: 0.1090, Validation Loss: 0.1345\n",
            "Epoch 2100/5000, Loss: 0.1072, Validation Loss: 0.1339\n",
            "Epoch 2200/5000, Loss: 0.1057, Validation Loss: 0.1328\n",
            "Epoch 2300/5000, Loss: 0.1053, Validation Loss: 0.1321\n",
            "Epoch 2400/5000, Loss: 0.1035, Validation Loss: 0.1276\n",
            "Epoch 2500/5000, Loss: 0.1024, Validation Loss: 0.1270\n",
            "Epoch 2600/5000, Loss: 0.1013, Validation Loss: 0.1266\n",
            "Epoch 2700/5000, Loss: 0.1003, Validation Loss: 0.1262\n",
            "Epoch 2800/5000, Loss: 0.0979, Validation Loss: 0.1261\n",
            "Epoch 2900/5000, Loss: 0.0971, Validation Loss: 0.1255\n",
            "Epoch 3000/5000, Loss: 0.0965, Validation Loss: 0.1251\n",
            "Epoch 3100/5000, Loss: 0.0958, Validation Loss: 0.1247\n",
            "Epoch 3200/5000, Loss: 0.0952, Validation Loss: 0.1242\n",
            "Epoch 3300/5000, Loss: 0.0946, Validation Loss: 0.1238\n",
            "Epoch 3400/5000, Loss: 0.0941, Validation Loss: 0.1235\n",
            "Epoch 3500/5000, Loss: 0.0936, Validation Loss: 0.1232\n",
            "Epoch 3600/5000, Loss: 0.0932, Validation Loss: 0.1230\n",
            "Epoch 3700/5000, Loss: 0.0927, Validation Loss: 0.1227\n",
            "Epoch 3800/5000, Loss: 0.0923, Validation Loss: 0.1225\n",
            "Epoch 3900/5000, Loss: 0.0920, Validation Loss: 0.1223\n",
            "Epoch 4000/5000, Loss: 0.0916, Validation Loss: 0.1220\n",
            "Epoch 4100/5000, Loss: 0.0912, Validation Loss: 0.1218\n",
            "Epoch 4200/5000, Loss: 0.0909, Validation Loss: 0.1216\n",
            "Epoch 4300/5000, Loss: 0.0906, Validation Loss: 0.1213\n",
            "Epoch 4400/5000, Loss: 0.0902, Validation Loss: 0.1210\n",
            "Epoch 4500/5000, Loss: 0.0899, Validation Loss: 0.1209\n",
            "Epoch 4600/5000, Loss: 0.0896, Validation Loss: 0.1207\n",
            "Epoch 4700/5000, Loss: 0.0894, Validation Loss: 0.1206\n",
            "Epoch 4800/5000, Loss: 0.0891, Validation Loss: 0.1205\n",
            "Epoch 4900/5000, Loss: 0.0889, Validation Loss: 0.1204\n",
            "Completeness: 0.5851181276219916\n",
            "Purity: 0.2724655562410035\n",
            "SNPCC Figure of Merit: 0.06493688911124373\n",
            "40\n",
            "Epoch 0/5000, Loss: nan, Validation Loss: nan\n",
            "Epoch 100/5000, Loss: 0.4507, Validation Loss: 0.5246\n",
            "Epoch 200/5000, Loss: 0.2895, Validation Loss: 0.3691\n",
            "Epoch 300/5000, Loss: 0.2209, Validation Loss: 0.2982\n",
            "Epoch 400/5000, Loss: 0.1960, Validation Loss: 0.2229\n",
            "Epoch 500/5000, Loss: 0.1660, Validation Loss: 0.1879\n",
            "Epoch 600/5000, Loss: 0.1431, Validation Loss: 0.1652\n",
            "Epoch 700/5000, Loss: 0.1327, Validation Loss: 0.1551\n",
            "Epoch 800/5000, Loss: 0.1201, Validation Loss: 0.1430\n",
            "Epoch 900/5000, Loss: 0.1125, Validation Loss: 0.1338\n",
            "Epoch 1000/5000, Loss: 0.1069, Validation Loss: 0.1285\n",
            "Epoch 1100/5000, Loss: 0.1010, Validation Loss: 0.1254\n",
            "Epoch 1200/5000, Loss: 0.0979, Validation Loss: 0.1235\n",
            "Epoch 1300/5000, Loss: 0.0956, Validation Loss: 0.1201\n",
            "Epoch 1400/5000, Loss: 0.0929, Validation Loss: 0.1182\n",
            "Epoch 1500/5000, Loss: 0.0903, Validation Loss: 0.1166\n",
            "Epoch 1600/5000, Loss: 0.0885, Validation Loss: 0.1142\n",
            "Epoch 1700/5000, Loss: 0.0864, Validation Loss: 0.1133\n",
            "Epoch 1800/5000, Loss: 0.0854, Validation Loss: 0.1117\n",
            "Epoch 1900/5000, Loss: 0.0838, Validation Loss: 0.1104\n",
            "Epoch 2000/5000, Loss: 0.0837, Validation Loss: 0.1094\n",
            "Epoch 2100/5000, Loss: 0.1002, Validation Loss: 0.1102\n",
            "Epoch 2200/5000, Loss: 0.0945, Validation Loss: 0.1096\n",
            "Epoch 2300/5000, Loss: 0.0901, Validation Loss: 0.1117\n",
            "Epoch 2400/5000, Loss: 0.0870, Validation Loss: 0.1112\n",
            "Epoch 2500/5000, Loss: 0.0829, Validation Loss: 0.1072\n",
            "Epoch 2600/5000, Loss: 0.0842, Validation Loss: 0.1050\n",
            "Epoch 2700/5000, Loss: 0.0823, Validation Loss: 0.0946\n",
            "Epoch 2800/5000, Loss: 0.0765, Validation Loss: 0.1005\n",
            "Epoch 2900/5000, Loss: 0.0774, Validation Loss: 0.1000\n",
            "Epoch 3000/5000, Loss: 0.0806, Validation Loss: 0.0939\n",
            "Epoch 3100/5000, Loss: 0.0793, Validation Loss: 0.1047\n",
            "Epoch 3200/5000, Loss: 0.0772, Validation Loss: 0.1043\n",
            "Epoch 3300/5000, Loss: 0.0762, Validation Loss: 0.1039\n",
            "Epoch 3400/5000, Loss: 0.0754, Validation Loss: 0.1038\n",
            "Epoch 3500/5000, Loss: 0.0742, Validation Loss: 0.1041\n",
            "Epoch 3600/5000, Loss: 0.0737, Validation Loss: 0.1041\n",
            "Epoch 3700/5000, Loss: 0.0732, Validation Loss: 0.1038\n",
            "Epoch 3800/5000, Loss: 0.0728, Validation Loss: 0.1036\n",
            "Epoch 3900/5000, Loss: 0.0724, Validation Loss: 0.1034\n",
            "Epoch 4000/5000, Loss: 0.0721, Validation Loss: 0.1033\n",
            "Epoch 4100/5000, Loss: 0.0717, Validation Loss: 0.1031\n",
            "Epoch 4200/5000, Loss: 0.0714, Validation Loss: 0.1030\n",
            "Epoch 4300/5000, Loss: 0.0717, Validation Loss: 0.1011\n",
            "Epoch 4400/5000, Loss: 0.0713, Validation Loss: 0.1020\n",
            "Epoch 4500/5000, Loss: 0.0710, Validation Loss: 0.1021\n",
            "Epoch 4600/5000, Loss: 0.0716, Validation Loss: 0.1022\n",
            "Epoch 4700/5000, Loss: 0.0713, Validation Loss: 0.1018\n",
            "Epoch 4800/5000, Loss: 0.0710, Validation Loss: 0.1017\n",
            "Epoch 4900/5000, Loss: 0.0726, Validation Loss: 0.1015\n",
            "Completeness: 0.6069772576727754\n",
            "Purity: 0.2649893965683439\n",
            "SNPCC Figure of Merit: 0.06511787704271228\n",
            "50\n",
            "Epoch 0/5000, Loss: nan, Validation Loss: 6.0206\n",
            "Epoch 100/5000, Loss: 0.7964, Validation Loss: 1.0481\n",
            "Epoch 200/5000, Loss: 0.4822, Validation Loss: 0.8423\n",
            "Epoch 300/5000, Loss: 0.3972, Validation Loss: 0.6874\n",
            "Epoch 400/5000, Loss: 0.3599, Validation Loss: 0.6355\n",
            "Epoch 500/5000, Loss: 0.3314, Validation Loss: 0.6051\n",
            "Epoch 600/5000, Loss: 0.3014, Validation Loss: 0.5540\n",
            "Epoch 700/5000, Loss: 0.2757, Validation Loss: 0.5228\n",
            "Epoch 800/5000, Loss: 0.2578, Validation Loss: 0.4746\n",
            "Epoch 900/5000, Loss: 0.2381, Validation Loss: 0.4558\n",
            "Epoch 1000/5000, Loss: 0.2196, Validation Loss: 0.4005\n",
            "Epoch 1100/5000, Loss: 0.2055, Validation Loss: 0.3594\n",
            "Epoch 1200/5000, Loss: 0.1992, Validation Loss: 0.3168\n",
            "Epoch 1300/5000, Loss: 0.1856, Validation Loss: 0.2988\n",
            "Epoch 1400/5000, Loss: 0.1800, Validation Loss: 0.2762\n",
            "Epoch 1500/5000, Loss: 0.1705, Validation Loss: 0.2566\n",
            "Epoch 1600/5000, Loss: 0.1687, Validation Loss: 0.2516\n",
            "Epoch 1700/5000, Loss: 0.1578, Validation Loss: 0.2377\n",
            "Epoch 1800/5000, Loss: 0.1542, Validation Loss: 0.2287\n",
            "Epoch 1900/5000, Loss: 0.1581, Validation Loss: 0.2371\n",
            "Epoch 2000/5000, Loss: 0.1516, Validation Loss: 0.2167\n",
            "Epoch 2100/5000, Loss: 0.1470, Validation Loss: 0.2060\n",
            "Epoch 2200/5000, Loss: 0.1422, Validation Loss: 0.1971\n",
            "Epoch 2300/5000, Loss: 0.1386, Validation Loss: 0.1909\n",
            "Epoch 2400/5000, Loss: 0.1457, Validation Loss: 0.2000\n",
            "Epoch 2500/5000, Loss: 0.1324, Validation Loss: 0.1793\n",
            "Epoch 2600/5000, Loss: 0.1289, Validation Loss: 0.1759\n",
            "Epoch 2700/5000, Loss: 0.1276, Validation Loss: 0.1729\n",
            "Epoch 2800/5000, Loss: 0.1254, Validation Loss: 0.1692\n",
            "Epoch 2900/5000, Loss: 0.1224, Validation Loss: 0.1672\n",
            "Epoch 3000/5000, Loss: 0.1196, Validation Loss: 0.1647\n",
            "Epoch 3100/5000, Loss: 0.1179, Validation Loss: 0.1630\n",
            "Epoch 3200/5000, Loss: 0.1167, Validation Loss: 0.1627\n",
            "Epoch 3300/5000, Loss: 0.1149, Validation Loss: 0.1609\n",
            "Epoch 3400/5000, Loss: 0.1128, Validation Loss: 0.1596\n",
            "Epoch 3500/5000, Loss: 0.1120, Validation Loss: 0.1581\n",
            "Epoch 3600/5000, Loss: 0.1125, Validation Loss: 0.1570\n",
            "Epoch 3700/5000, Loss: 0.1112, Validation Loss: 0.1559\n",
            "Epoch 3800/5000, Loss: 0.1097, Validation Loss: 0.1547\n",
            "Epoch 3900/5000, Loss: 0.1090, Validation Loss: 0.1542\n",
            "Epoch 4000/5000, Loss: 0.1078, Validation Loss: 0.1535\n",
            "Epoch 4100/5000, Loss: 0.1084, Validation Loss: 0.1559\n",
            "Epoch 4200/5000, Loss: 0.1094, Validation Loss: 0.1556\n",
            "Epoch 4300/5000, Loss: 0.1084, Validation Loss: 0.1564\n",
            "Epoch 4400/5000, Loss: 0.1068, Validation Loss: 0.1561\n",
            "Epoch 4500/5000, Loss: 0.1052, Validation Loss: 0.1548\n",
            "Epoch 4600/5000, Loss: 0.1035, Validation Loss: 0.1537\n",
            "Epoch 4700/5000, Loss: 0.1026, Validation Loss: 0.1528\n",
            "Epoch 4800/5000, Loss: 0.1019, Validation Loss: 0.1523\n",
            "Epoch 4900/5000, Loss: 0.1010, Validation Loss: 0.1516\n",
            "Completeness: 0.6219916096268492\n",
            "Purity: 0.2901132852729145\n",
            "SNPCC Figure of Merit: 0.07457228312558879\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = pd.DataFrame(columns=['Sample Size','Z Used','COMPLENETENESS','PURITY','FOM'])"
      ],
      "metadata": {
        "id": "8qL1G1hFk6IN"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res['Sample Size'] = GLOBAL_SAMPLE_SIZE\n",
        "res['Z Used'] = GLOBAL_Z_USED\n",
        "res['COMPLENETENESS'] = GLOBAL_COMPLETENESS\n",
        "res['PURITY'] = GLOBAL_PURITY\n",
        "res['FOM'] = GLOBAL_FOM"
      ],
      "metadata": {
        "id": "Lh6TKr6ElbEt"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "SpbhbMIRljqH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "8d496a81-754e-4408-98b2-7584f860fe77"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sample Size Z Used  COMPLENETENESS    PURITY       FOM\n",
              "0             5     no        0.578053  0.248812  0.057476\n",
              "1            10     no        0.554869  0.266433  0.059922\n",
              "2            20     no        0.594612  0.250465  0.059594\n",
              "3            30     no        0.527710  0.263245  0.056162\n",
              "4            40     no        0.649150  0.271619  0.071770\n",
              "5            50     no        0.622875  0.264386  0.066639\n",
              "6           100     no        0.647163  0.274721  0.072551\n",
              "7             5    yes        0.596820  0.290458  0.071660\n",
              "8            10    yes        0.606756  0.280867  0.069893\n",
              "9            20    yes        0.567675  0.259487  0.059372\n",
              "10           30    yes        0.558843  0.275258  0.062799\n",
              "11           40    yes        0.585118  0.272466  0.064937\n",
              "12           50    yes        0.606977  0.264989  0.065118\n",
              "13          100    yes        0.621992  0.290113  0.074572"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c84f4c2-4a78-4906-8768-e51c94c995b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sample Size</th>\n",
              "      <th>Z Used</th>\n",
              "      <th>COMPLENETENESS</th>\n",
              "      <th>PURITY</th>\n",
              "      <th>FOM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>no</td>\n",
              "      <td>0.578053</td>\n",
              "      <td>0.248812</td>\n",
              "      <td>0.057476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>no</td>\n",
              "      <td>0.554869</td>\n",
              "      <td>0.266433</td>\n",
              "      <td>0.059922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>no</td>\n",
              "      <td>0.594612</td>\n",
              "      <td>0.250465</td>\n",
              "      <td>0.059594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>no</td>\n",
              "      <td>0.527710</td>\n",
              "      <td>0.263245</td>\n",
              "      <td>0.056162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40</td>\n",
              "      <td>no</td>\n",
              "      <td>0.649150</td>\n",
              "      <td>0.271619</td>\n",
              "      <td>0.071770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>50</td>\n",
              "      <td>no</td>\n",
              "      <td>0.622875</td>\n",
              "      <td>0.264386</td>\n",
              "      <td>0.066639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>100</td>\n",
              "      <td>no</td>\n",
              "      <td>0.647163</td>\n",
              "      <td>0.274721</td>\n",
              "      <td>0.072551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.596820</td>\n",
              "      <td>0.290458</td>\n",
              "      <td>0.071660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.606756</td>\n",
              "      <td>0.280867</td>\n",
              "      <td>0.069893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.567675</td>\n",
              "      <td>0.259487</td>\n",
              "      <td>0.059372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>30</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.558843</td>\n",
              "      <td>0.275258</td>\n",
              "      <td>0.062799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>40</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.585118</td>\n",
              "      <td>0.272466</td>\n",
              "      <td>0.064937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>50</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.606977</td>\n",
              "      <td>0.264989</td>\n",
              "      <td>0.065118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>100</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.621992</td>\n",
              "      <td>0.290113</td>\n",
              "      <td>0.074572</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c84f4c2-4a78-4906-8768-e51c94c995b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c84f4c2-4a78-4906-8768-e51c94c995b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c84f4c2-4a78-4906-8768-e51c94c995b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-71671b10-01e8-4bb5-8720-d2588fddd42f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71671b10-01e8-4bb5-8720-d2588fddd42f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-71671b10-01e8-4bb5-8720-d2588fddd42f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4870aa9d-bd71-48c1-8fb9-53642cede081\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('res')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4870aa9d-bd71-48c1-8fb9-53642cede081 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('res');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOBTJPfGZ5wr5hG1NRrCdsm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}